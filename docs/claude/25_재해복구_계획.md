# 25. ì¬í•´ë³µêµ¬ ê³„íš (Disaster Recovery Plan)

## 1. ê°œìš”

### 1.1 ëª©ì 
K-ERP SaaS í”Œë«í¼ì˜ ì¬í•´ ìƒí™©ì—ì„œ ë¹„ì¦ˆë‹ˆìŠ¤ ì—°ì†ì„±ì„ ë³´ì¥í•˜ê¸° ìœ„í•œ ë³µêµ¬ ê³„íšì„ ì •ì˜í•œë‹¤.

### 1.2 ì ìš© ë²”ìœ„
- ëª¨ë“  í”„ë¡œë•ì…˜ í™˜ê²½ ì„œë¹„ìŠ¤
- ê³ ê° ë°ì´í„° ë° íŠ¸ëœì­ì…˜
- ì™¸ë¶€ ì‹œìŠ¤í…œ ì—°ë™ (Popbill, 4ëŒ€ë³´í—˜ EDI)

### 1.3 í•µì‹¬ ëª©í‘œ
| ì§€í‘œ | ëª©í‘œê°’ | ì„¤ëª… |
|------|--------|------|
| **RPO** | 1ì‹œê°„ | ë°ì´í„° ì†ì‹¤ í—ˆìš© ë²”ìœ„ |
| **RTO** | 4ì‹œê°„ | ì„œë¹„ìŠ¤ ë³µêµ¬ ëª©í‘œ ì‹œê°„ |
| **ê°€ë™ë¥ ** | 99.9% | ì—°ê°„ ë‹¤ìš´íƒ€ì„ 8.76ì‹œê°„ ì´ë‚´ |

## 2. ì¬í•´ ìœ í˜• ë° ëŒ€ì‘ ìˆ˜ì¤€

### 2.1 ì¬í•´ ë“±ê¸‰ ë¶„ë¥˜
| ë“±ê¸‰ | ìœ í˜• | ì˜í–¥ ë²”ìœ„ | ëŒ€ì‘ ìˆ˜ì¤€ |
|------|------|-----------|-----------|
| **Level 1** | ê²½ë¯¸ | ë‹¨ì¼ Pod/ì„œë¹„ìŠ¤ ì¥ì•  | ìë™ ë³µêµ¬ |
| **Level 2** | ë³´í†µ | ë‹¨ì¼ ë…¸ë“œ/AZ ì¥ì•  | ìˆ˜ë™ ê°œì… í•„ìš” |
| **Level 3** | ì‹¬ê° | ë¦¬ì „ ì¥ì•  | DR ì‚¬ì´íŠ¸ í™œì„±í™” |
| **Level 4** | ì¹˜ëª… | ì „ì²´ í´ë¼ìš°ë“œ ì¥ì•  | ë¹„ìƒ ê³„íš ê°€ë™ |

### 2.2 ì ì¬ì  ì¬í•´ ì‹œë‚˜ë¦¬ì˜¤
```yaml
scenarios:
  - id: S1
    name: ë‹¨ì¼ Pod ì¥ì• 
    cause: OOM, ë²„ê·¸, ë¦¬ì†ŒìŠ¤ ë¶€ì¡±
    probability: ë†’ìŒ
    impact: ë‚®ìŒ
    recovery: ìë™ (K8s ì¬ì‹œì‘)

  - id: S2
    name: ë°ì´í„°ë² ì´ìŠ¤ ì¥ì• 
    cause: ë””ìŠ¤í¬ ì¥ì• , ë„¤íŠ¸ì›Œí¬ ë‹¨ì ˆ
    probability: ë‚®ìŒ
    impact: ë†’ìŒ
    recovery: ìë™ í˜ì¼ì˜¤ë²„ (RDS Multi-AZ)

  - id: S3
    name: ê°€ìš© ì˜ì—­(AZ) ì¥ì• 
    cause: AWS AZ ì¥ì• 
    probability: ë§¤ìš° ë‚®ìŒ
    impact: ë†’ìŒ
    recovery: ë‹¤ë¥¸ AZë¡œ ìë™ ì „í™˜

  - id: S4
    name: ë¦¬ì „ ì¥ì• 
    cause: ëŒ€ê·œëª¨ ìì—°ì¬í•´, AWS ë¦¬ì „ ì¥ì• 
    probability: ê·¹íˆ ë‚®ìŒ
    impact: ì¹˜ëª…ì 
    recovery: DR ë¦¬ì „ í™œì„±í™” (ìˆ˜ë™)

  - id: S5
    name: ì‚¬ì´ë²„ ê³µê²© (ëœì„¬ì›¨ì–´)
    cause: ì•…ì„±ì½”ë“œ ê°ì—¼
    probability: ë‚®ìŒ
    impact: ì¹˜ëª…ì 
    recovery: ê²©ë¦¬ í›„ ë°±ì—… ë³µì›
```

## 3. ì¸í”„ë¼ ì•„í‚¤í…ì²˜

### 3.1 Multi-AZ êµ¬ì„± (Primary Region: ap-northeast-2)
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    AWS ap-northeast-2 (ì„œìš¸)                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚       AZ-a          â”‚       AZ-b          â”‚        AZ-c             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚   EKS Node    â”‚  â”‚  â”‚   EKS Node    â”‚  â”‚  â”‚    EKS Node       â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”‚
â”‚  â”‚  â”‚API Pod x3â”‚ â”‚  â”‚  â”‚  â”‚API Pod x3â”‚ â”‚  â”‚  â”‚  â”‚Worker Pod x2â”‚  â”‚  â”‚
â”‚  â”‚  â”‚Worker x2 â”‚ â”‚  â”‚  â”‚  â”‚Worker x2 â”‚ â”‚  â”‚  â”‚  â”‚             â”‚  â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚                         â”‚
â”‚  â”‚RDS Primary    â”‚  â”‚  â”‚RDS Standby    â”‚  â”‚                         â”‚
â”‚  â”‚(PostgreSQL)   â”‚â”€â”€â”¼â”€â”€â”‚(Sync Replica) â”‚  â”‚                         â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ElastiCache    â”‚  â”‚  â”‚ElastiCache    â”‚  â”‚  â”‚ElastiCache        â”‚  â”‚
â”‚  â”‚Primary        â”‚â”€â”€â”¼â”€â”€â”‚Replica        â”‚â”€â”€â”¼â”€â”€â”‚Replica            â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                                â”‚ Cross-Region Replication
                                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    AWS ap-northeast-1 (ë„ì¿„) - DR Site              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ EKS Cluster     â”‚  â”‚ RDS Read        â”‚  â”‚ S3 Bucket           â”‚  â”‚
â”‚  â”‚ (Standby)       â”‚  â”‚ Replica         â”‚  â”‚ (Cross-Region)      â”‚  â”‚
â”‚  â”‚ - ìµœì†Œ ë…¸ë“œ     â”‚  â”‚ - Async Replica â”‚  â”‚ - ë°±ì—… ì €ì¥         â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 3.2 Kubernetes ê³ ê°€ìš©ì„± ì„¤ì •
```yaml
# deployments/k8s/production/api-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: kerp-api
  namespace: production
spec:
  replicas: 6
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxUnavailable: 1
      maxSurge: 2
  selector:
    matchLabels:
      app: kerp-api
  template:
    metadata:
      labels:
        app: kerp-api
    spec:
      # Pod Anti-Affinity: ë‹¤ë¥¸ ë…¸ë“œ/AZì— ë¶„ì‚° ë°°ì¹˜
      affinity:
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            - labelSelector:
                matchExpressions:
                  - key: app
                    operator: In
                    values:
                      - kerp-api
              topologyKey: kubernetes.io/hostname
          preferredDuringSchedulingIgnoredDuringExecution:
            - weight: 100
              podAffinityTerm:
                labelSelector:
                  matchExpressions:
                    - key: app
                      operator: In
                      values:
                        - kerp-api
                topologyKey: topology.kubernetes.io/zone

      # Topology Spread: AZë³„ ê· ë“± ë¶„ë°°
      topologySpreadConstraints:
        - maxSkew: 1
          topologyKey: topology.kubernetes.io/zone
          whenUnsatisfiable: DoNotSchedule
          labelSelector:
            matchLabels:
              app: kerp-api

      containers:
        - name: api
          image: kerp/api:latest
          resources:
            requests:
              memory: "512Mi"
              cpu: "250m"
            limits:
              memory: "1Gi"
              cpu: "1000m"

          # ìƒíƒœ í™•ì¸
          livenessProbe:
            httpGet:
              path: /health/live
              port: 8080
            initialDelaySeconds: 30
            periodSeconds: 10
            failureThreshold: 3

          readinessProbe:
            httpGet:
              path: /health/ready
              port: 8080
            initialDelaySeconds: 5
            periodSeconds: 5
            failureThreshold: 3

---
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  name: kerp-api-pdb
  namespace: production
spec:
  minAvailable: 4  # ìµœì†Œ 4ê°œ Pod ìœ ì§€
  selector:
    matchLabels:
      app: kerp-api
```

## 4. ë°±ì—… ì „ëµ

### 4.1 ë°±ì—… ì •ì±…
| ëŒ€ìƒ | ë°©ì‹ | ì£¼ê¸° | ë³´ì¡´ ê¸°ê°„ | ì €ì¥ ìœ„ì¹˜ |
|------|------|------|-----------|-----------|
| **PostgreSQL** | ìë™ ìŠ¤ëƒ…ìƒ· | 1ì‹œê°„ | 7ì¼ | RDS + S3 |
| **PostgreSQL** | ì¼ì¼ ë°±ì—… | ë§¤ì¼ 03:00 | 30ì¼ | S3 (Cross-Region) |
| **PostgreSQL** | WAL ì•„ì¹´ì´ë¸Œ | ì‹¤ì‹œê°„ | 7ì¼ | S3 |
| **Redis** | AOF Backup | 1ì‹œê°„ | 24ì‹œê°„ | ElastiCache |
| **MinIO (íŒŒì¼)** | Versioning | ì‹¤ì‹œê°„ | 90ì¼ | S3 Cross-Region |
| **ì„¤ì • íŒŒì¼** | GitOps | ë³€ê²½ ì‹œ | ë¬´ì œí•œ | Git Repository |
| **ì‹œí¬ë¦¿** | Sealed Secrets | ë³€ê²½ ì‹œ | ë¬´ì œí•œ | Git + AWS Secrets Manager |

### 4.2 PostgreSQL ë°±ì—… ì„¤ì •
```yaml
# AWS RDS ì„¤ì •
resource "aws_db_instance" "kerp_primary" {
  identifier     = "kerp-production"
  engine         = "postgres"
  engine_version = "16.1"
  instance_class = "db.r6g.xlarge"

  # Multi-AZ í™œì„±í™”
  multi_az = true

  # ìë™ ë°±ì—…
  backup_retention_period = 7       # 7ì¼ ë³´ì¡´
  backup_window           = "03:00-04:00"  # KST 12:00-13:00

  # ìŠ¤ëƒ…ìƒ·
  copy_tags_to_snapshot = true
  delete_automated_backups_on_deletion = false

  # ì•”í˜¸í™”
  storage_encrypted = true
  kms_key_id       = aws_kms_key.rds.arn

  # ì„±ëŠ¥ ì¸ì‚¬ì´íŠ¸
  performance_insights_enabled = true
  performance_insights_retention_period = 7
}

# Cross-Region ì½ê¸° ì „ìš© ë³µì œë³¸ (DRìš©)
resource "aws_db_instance" "kerp_dr_replica" {
  provider = aws.tokyo

  identifier          = "kerp-dr-replica"
  replicate_source_db = aws_db_instance.kerp_primary.arn

  instance_class = "db.r6g.large"

  # ì•”í˜¸í™” (ë‹¤ë¥¸ KMS í‚¤ ì‚¬ìš©)
  storage_encrypted = true
  kms_key_id       = aws_kms_key.rds_tokyo.arn
}
```

### 4.3 ìë™ ë°±ì—… ìŠ¤í¬ë¦½íŠ¸
```go
// internal/backup/scheduler.go
package backup

import (
    "context"
    "fmt"
    "time"

    "github.com/aws/aws-sdk-go-v2/service/rds"
    "github.com/aws/aws-sdk-go-v2/service/s3"
    "github.com/robfig/cron/v3"
)

type BackupScheduler struct {
    rdsClient *rds.Client
    s3Client  *s3.Client
    cron      *cron.Cron
    config    BackupConfig
}

type BackupConfig struct {
    DBIdentifier     string
    S3Bucket         string
    RetentionDays    int
    CrossRegionCopy  bool
    DRRegion         string
}

func (s *BackupScheduler) Start() error {
    // ë§¤ì‹œê°„ ì¦ë¶„ ë°±ì—… í™•ì¸
    s.cron.AddFunc("0 * * * *", s.checkPointInTimeRecovery)

    // ë§¤ì¼ 03:00 ì „ì²´ ë°±ì—…
    s.cron.AddFunc("0 3 * * *", s.createDailySnapshot)

    // ë§¤ì£¼ ì¼ìš”ì¼ Cross-Region ë³µì œ
    s.cron.AddFunc("0 4 * * 0", s.crossRegionBackup)

    // ë§¤ì¼ 05:00 ì˜¤ë˜ëœ ë°±ì—… ì •ë¦¬
    s.cron.AddFunc("0 5 * * *", s.cleanupOldBackups)

    s.cron.Start()
    return nil
}

func (s *BackupScheduler) createDailySnapshot(ctx context.Context) error {
    snapshotID := fmt.Sprintf("kerp-daily-%s", time.Now().Format("2006-01-02"))

    input := &rds.CreateDBSnapshotInput{
        DBInstanceIdentifier: &s.config.DBIdentifier,
        DBSnapshotIdentifier: &snapshotID,
        Tags: []types.Tag{
            {Key: aws.String("Type"), Value: aws.String("daily")},
            {Key: aws.String("RetentionDays"), Value: aws.String("30")},
        },
    }

    _, err := s.rdsClient.CreateDBSnapshot(ctx, input)
    if err != nil {
        log.Error("failed to create daily snapshot", "error", err)
        // ì•Œë¦¼ ë°œì†¡
        s.sendAlert(AlertLevelHigh, "Daily backup failed", err.Error())
        return err
    }

    log.Info("daily snapshot created", "snapshot_id", snapshotID)
    return nil
}

func (s *BackupScheduler) crossRegionBackup(ctx context.Context) error {
    if !s.config.CrossRegionCopy {
        return nil
    }

    // ê°€ì¥ ìµœê·¼ ìŠ¤ëƒ…ìƒ· ì°¾ê¸°
    latestSnapshot, err := s.findLatestSnapshot(ctx)
    if err != nil {
        return err
    }

    // Cross-Region ë³µì‚¬
    copyInput := &rds.CopyDBSnapshotInput{
        SourceDBSnapshotIdentifier: latestSnapshot.DBSnapshotIdentifier,
        TargetDBSnapshotIdentifier: aws.String(
            fmt.Sprintf("kerp-dr-%s", time.Now().Format("2006-01-02")),
        ),
        SourceRegion: aws.String("ap-northeast-2"),
        KmsKeyId:     aws.String(s.config.DRKMSKeyID),
    }

    drClient := rds.NewFromConfig(s.drConfig)
    _, err = drClient.CopyDBSnapshot(ctx, copyInput)
    if err != nil {
        s.sendAlert(AlertLevelCritical, "Cross-region backup failed", err.Error())
        return err
    }

    log.Info("cross-region backup completed", "dr_region", s.config.DRRegion)
    return nil
}
```

## 5. ë³µêµ¬ ì ˆì°¨

### 5.1 Level 1: Pod ì¥ì•  ë³µêµ¬ (ìë™)
```yaml
# Kubernetes ìë™ ë³µêµ¬
# - livenessProbe ì‹¤íŒ¨ â†’ Pod ì¬ì‹œì‘
# - readinessProbe ì‹¤íŒ¨ â†’ íŠ¸ë˜í”½ ì œì™¸

# ìë™ ë³µêµ¬ í™•ì¸
kubectl get events -n production --field-selector reason=Killing
kubectl get pods -n production -o wide
```

### 5.2 Level 2: ë…¸ë“œ/ì„œë¹„ìŠ¤ ì¥ì•  ë³µêµ¬
```bash
#!/bin/bash
# scripts/recovery/level2-recovery.sh

set -e

echo "=== Level 2 Recovery: Node/Service Failure ==="

# 1. ìƒíƒœ í™•ì¸
echo "[1/5] Checking cluster status..."
kubectl get nodes
kubectl get pods -n production -o wide

# 2. ë¬¸ì œ ë…¸ë“œ í™•ì¸
PROBLEM_NODE=$(kubectl get nodes | grep NotReady | awk '{print $1}')
if [ -n "$PROBLEM_NODE" ]; then
    echo "Problem node detected: $PROBLEM_NODE"

    # 3. ë…¸ë“œ drain (ì•ˆì „í•˜ê²Œ Pod ì´ë™)
    echo "[2/5] Draining node..."
    kubectl drain $PROBLEM_NODE --ignore-daemonsets --delete-emptydir-data

    # 4. ë…¸ë“œ êµì²´ (ASG í™œìš©)
    echo "[3/5] Terminating unhealthy node..."
    INSTANCE_ID=$(kubectl get node $PROBLEM_NODE -o jsonpath='{.spec.providerID}' | cut -d'/' -f5)
    aws ec2 terminate-instances --instance-ids $INSTANCE_ID

    # 5. ìƒˆ ë…¸ë“œ ëŒ€ê¸°
    echo "[4/5] Waiting for new node..."
    sleep 120
    kubectl get nodes
fi

# 6. Pod ìƒíƒœ í™•ì¸
echo "[5/5] Verifying pod distribution..."
kubectl get pods -n production -o wide
kubectl top pods -n production

echo "=== Level 2 Recovery Complete ==="
```

### 5.3 Level 3: ë¦¬ì „ ì¥ì•  ë³µêµ¬ (DR í™œì„±í™”)
```bash
#!/bin/bash
# scripts/recovery/level3-dr-activation.sh

set -e

# í™˜ê²½ ë³€ìˆ˜
PRIMARY_REGION="ap-northeast-2"
DR_REGION="ap-northeast-1"
DR_CLUSTER="kerp-dr-cluster"

echo "=== Level 3 Recovery: DR Site Activation ==="
echo "WARNING: This will activate DR site in $DR_REGION"
read -p "Continue? (yes/no): " confirm
if [ "$confirm" != "yes" ]; then
    exit 1
fi

# 1. Primary ë¦¬ì „ ìƒíƒœ í™•ì¸
echo "[1/8] Verifying primary region is unavailable..."
if aws rds describe-db-instances --region $PRIMARY_REGION 2>/dev/null; then
    echo "WARNING: Primary region seems available. Are you sure?"
    read -p "Force DR activation? (yes/no): " force
    if [ "$force" != "yes" ]; then
        exit 1
    fi
fi

# 2. DR RDS ë³µì œë³¸ ìŠ¹ê²©
echo "[2/8] Promoting DR database replica..."
aws rds promote-read-replica \
    --db-instance-identifier kerp-dr-replica \
    --region $DR_REGION

# 3. ìŠ¹ê²© ì™„ë£Œ ëŒ€ê¸°
echo "[3/8] Waiting for database promotion..."
aws rds wait db-instance-available \
    --db-instance-identifier kerp-dr-replica \
    --region $DR_REGION

# 4. DR EKS í´ëŸ¬ìŠ¤í„° ìŠ¤ì¼€ì¼ ì—…
echo "[4/8] Scaling up DR Kubernetes cluster..."
aws eks update-nodegroup-config \
    --cluster-name $DR_CLUSTER \
    --nodegroup-name production-nodes \
    --scaling-config minSize=3,maxSize=10,desiredSize=6 \
    --region $DR_REGION

# 5. ConfigMap ì—…ë°ì´íŠ¸ (DB ì—”ë“œí¬ì¸íŠ¸)
echo "[5/8] Updating database connection..."
kubectl config use-context arn:aws:eks:$DR_REGION:*:cluster/$DR_CLUSTER

DR_DB_ENDPOINT=$(aws rds describe-db-instances \
    --db-instance-identifier kerp-dr-replica \
    --region $DR_REGION \
    --query 'DBInstances[0].Endpoint.Address' \
    --output text)

kubectl create configmap db-config \
    --from-literal=DATABASE_HOST=$DR_DB_ENDPOINT \
    --from-literal=DATABASE_PORT=5432 \
    -n production \
    --dry-run=client -o yaml | kubectl apply -f -

# 6. ì• í”Œë¦¬ì¼€ì´ì…˜ ì¬ì‹œì‘
echo "[6/8] Restarting applications..."
kubectl rollout restart deployment/kerp-api -n production
kubectl rollout restart deployment/kerp-worker -n production

# 7. DNS ì „í™˜
echo "[7/8] Updating DNS to DR site..."
aws route53 change-resource-record-sets \
    --hosted-zone-id $HOSTED_ZONE_ID \
    --change-batch '{
        "Changes": [{
            "Action": "UPSERT",
            "ResourceRecordSet": {
                "Name": "api.k-erp.io",
                "Type": "A",
                "AliasTarget": {
                    "HostedZoneId": "'$DR_ALB_ZONE_ID'",
                    "DNSName": "'$DR_ALB_DNS'",
                    "EvaluateTargetHealth": true
                }
            }
        }]
    }'

# 8. ìƒíƒœ í™•ì¸
echo "[8/8] Verifying DR site..."
kubectl get pods -n production
curl -s https://api.k-erp.io/health | jq .

echo "=== DR Activation Complete ==="
echo "Primary: $PRIMARY_REGION (INACTIVE)"
echo "DR Site: $DR_REGION (ACTIVE)"
```

### 5.4 Level 4: ë°ì´í„° ë³µì› ì ˆì°¨
```bash
#!/bin/bash
# scripts/recovery/restore-from-backup.sh

set -e

# íŒŒë¼ë¯¸í„°
SNAPSHOT_ID=${1:-"latest"}
RESTORE_DB_NAME="kerp-restored-$(date +%Y%m%d-%H%M)"

echo "=== Database Restore from Backup ==="

# 1. ì‚¬ìš© ê°€ëŠ¥í•œ ìŠ¤ëƒ…ìƒ· ëª©ë¡
if [ "$SNAPSHOT_ID" == "latest" ]; then
    echo "[1/6] Finding latest snapshot..."
    SNAPSHOT_ID=$(aws rds describe-db-snapshots \
        --db-instance-identifier kerp-production \
        --query 'DBSnapshots | sort_by(@, &SnapshotCreateTime) | [-1].DBSnapshotIdentifier' \
        --output text)
    echo "Latest snapshot: $SNAPSHOT_ID"
fi

# 2. ìŠ¤ëƒ…ìƒ·ì—ì„œ ë³µì›
echo "[2/6] Restoring from snapshot..."
aws rds restore-db-instance-from-db-snapshot \
    --db-instance-identifier $RESTORE_DB_NAME \
    --db-snapshot-identifier $SNAPSHOT_ID \
    --db-instance-class db.r6g.xlarge \
    --vpc-security-group-ids $DB_SECURITY_GROUP \
    --db-subnet-group-name kerp-db-subnet

# 3. ë³µì› ì™„ë£Œ ëŒ€ê¸°
echo "[3/6] Waiting for restore to complete..."
aws rds wait db-instance-available \
    --db-instance-identifier $RESTORE_DB_NAME

# 4. Point-in-Time Recovery (í•„ìš” ì‹œ)
echo "[4/6] Apply WAL logs for point-in-time recovery..."
RESTORE_TIME=${2:-$(date -u +%Y-%m-%dT%H:%M:%SZ)}
# PITRì€ ë³„ë„ ëª…ë ¹ìœ¼ë¡œ ìˆ˜í–‰

# 5. ë°ì´í„° ê²€ì¦
echo "[5/6] Verifying restored data..."
RESTORED_ENDPOINT=$(aws rds describe-db-instances \
    --db-instance-identifier $RESTORE_DB_NAME \
    --query 'DBInstances[0].Endpoint.Address' \
    --output text)

psql -h $RESTORED_ENDPOINT -U kerp_admin -d kerp -c "
    SELECT 'vouchers' as table_name, COUNT(*) as count FROM vouchers
    UNION ALL
    SELECT 'companies', COUNT(*) FROM companies
    UNION ALL
    SELECT 'users', COUNT(*) FROM users;
"

# 6. ë³µì› ì™„ë£Œ ë³´ê³ 
echo "[6/6] Restore complete"
echo "Restored DB: $RESTORE_DB_NAME"
echo "Endpoint: $RESTORED_ENDPOINT"
echo "From Snapshot: $SNAPSHOT_ID"
```

## 6. ëª¨ë‹ˆí„°ë§ ë° ì•Œë¦¼

### 6.1 ì¬í•´ ê°ì§€ ê·œì¹™
```yaml
# prometheus/rules/disaster-detection.yaml
groups:
  - name: disaster-detection
    rules:
      # ë‹¤ì¤‘ Pod ì¥ì• 
      - alert: MultiPodFailure
        expr: |
          sum(kube_pod_status_phase{namespace="production", phase="Running"}) < 3
        for: 2m
        labels:
          severity: critical
          level: "2"
        annotations:
          summary: "Multiple pods are down"
          runbook: "https://wiki.k-erp.io/runbook/multi-pod-failure"

      # ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì¥ì• 
      - alert: DatabaseConnectionFailure
        expr: |
          sum(pg_up) == 0
        for: 1m
        labels:
          severity: critical
          level: "2"
        annotations:
          summary: "Database connection lost"
          runbook: "https://wiki.k-erp.io/runbook/db-connection-failure"

      # ì „ì²´ AZ ì¥ì•  ê°ì§€
      - alert: AvailabilityZoneFailure
        expr: |
          count(kube_node_info) by (topology_kubernetes_io_zone) == 0
        for: 5m
        labels:
          severity: critical
          level: "3"
        annotations:
          summary: "Availability zone {{ $labels.topology_kubernetes_io_zone }} is down"
          runbook: "https://wiki.k-erp.io/runbook/az-failure"

      # ë°±ì—… ì‹¤íŒ¨
      - alert: BackupFailure
        expr: |
          time() - rds_backup_last_success_timestamp > 7200
        for: 10m
        labels:
          severity: high
          level: "2"
        annotations:
          summary: "Database backup has not succeeded in 2 hours"

      # RPO ìœ„ë°˜ ìœ„í—˜
      - alert: RPOAtRisk
        expr: |
          time() - rds_backup_last_success_timestamp > 3000
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "RPO (1h) may be violated - backup overdue"
```

### 6.2 ì•Œë¦¼ ì±„ë„ ì„¤ì •
```yaml
# alertmanager/config.yaml
global:
  resolve_timeout: 5m
  slack_api_url: 'https://hooks.slack.com/services/xxx'

route:
  group_by: ['alertname', 'level']
  group_wait: 30s
  group_interval: 5m
  repeat_interval: 4h
  receiver: 'default'

  routes:
    # Level 3+ ì¬í•´: ëª¨ë“  ì±„ë„ë¡œ ì¦‰ì‹œ ì•Œë¦¼
    - match:
        level: "3"
      receiver: 'disaster-all-channels'
      group_wait: 0s
      repeat_interval: 15m

    # Level 2 ì¬í•´: ìš´ì˜íŒ€ + Slack
    - match:
        level: "2"
      receiver: 'ops-team'
      group_wait: 30s

receivers:
  - name: 'disaster-all-channels'
    slack_configs:
      - channel: '#alerts-critical'
        title: 'ğŸš¨ [DISASTER] {{ .GroupLabels.alertname }}'
        text: '{{ range .Alerts }}{{ .Annotations.summary }}{{ end }}'
    pagerduty_configs:
      - service_key: $PAGERDUTY_KEY
        severity: critical
    email_configs:
      - to: 'disaster-team@k-erp.io,cto@k-erp.io'
        send_resolved: true
    webhook_configs:
      - url: 'https://sms-gateway.k-erp.io/emergency'

  - name: 'ops-team'
    slack_configs:
      - channel: '#alerts-ops'
    pagerduty_configs:
      - service_key: $PAGERDUTY_KEY
        severity: high
```

## 7. í…ŒìŠ¤íŠ¸ ë° í›ˆë ¨

### 7.1 DR í…ŒìŠ¤íŠ¸ ì¼ì •
| í…ŒìŠ¤íŠ¸ ìœ í˜• | ì£¼ê¸° | ë²”ìœ„ | ë‹´ë‹¹ |
|-------------|------|------|------|
| **ë°±ì—… ê²€ì¦** | ì£¼ 1íšŒ | ë°±ì—… ë³µì› í…ŒìŠ¤íŠ¸ | DevOps |
| **í˜ì¼ì˜¤ë²„ í…ŒìŠ¤íŠ¸** | ì›” 1íšŒ | DB í˜ì¼ì˜¤ë²„ | DBA |
| **DR í›ˆë ¨** | ë¶„ê¸° 1íšŒ | ì „ì²´ DR ì‹œë‚˜ë¦¬ì˜¤ | ì „ì²´ íŒ€ |
| **ì¹´ì˜¤ìŠ¤ í…ŒìŠ¤íŠ¸** | ì›” 1íšŒ | Pod/Node ì¥ì•  ì£¼ì… | SRE |

### 7.2 ì¹´ì˜¤ìŠ¤ ì—”ì§€ë‹ˆì–´ë§
```yaml
# chaos/pod-failure.yaml
apiVersion: chaos-mesh.org/v1alpha1
kind: PodChaos
metadata:
  name: pod-failure-test
  namespace: chaos-testing
spec:
  action: pod-failure
  mode: fixed-percent
  value: "30"  # 30% Pod ì¥ì• 
  duration: "5m"
  selector:
    namespaces:
      - staging  # Staging í™˜ê²½ì—ì„œë§Œ í…ŒìŠ¤íŠ¸
    labelSelectors:
      app: kerp-api
  scheduler:
    cron: "0 3 * * 1"  # ë§¤ì£¼ ì›”ìš”ì¼ 03:00

---
apiVersion: chaos-mesh.org/v1alpha1
kind: NetworkChaos
metadata:
  name: network-partition-test
  namespace: chaos-testing
spec:
  action: partition
  mode: all
  selector:
    namespaces:
      - staging
    labelSelectors:
      app: kerp-api
  direction: both
  target:
    selector:
      namespaces:
        - staging
      labelSelectors:
        app: kerp-database
  duration: "2m"
```

### 7.3 DR í›ˆë ¨ ì²´í¬ë¦¬ìŠ¤íŠ¸
```markdown
## DR í›ˆë ¨ ì²´í¬ë¦¬ìŠ¤íŠ¸

### ì‚¬ì „ ì¤€ë¹„
- [ ] í›ˆë ¨ ì¼ì • ê³µì§€ (ê³ ê°/ë‚´ë¶€)
- [ ] ë¡¤ë°± ê³„íš í™•ì¸
- [ ] ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ ì¤€ë¹„
- [ ] ë¹„ìƒ ì—°ë½ë§ í™•ì¸

### í›ˆë ¨ ì‹¤í–‰
- [ ] Primary DB ì ‘ê·¼ ì°¨ë‹¨ ì‹œë®¬ë ˆì´ì…˜
- [ ] DR ë³µì œë³¸ ìŠ¹ê²©
- [ ] EKS í´ëŸ¬ìŠ¤í„° ìŠ¤ì¼€ì¼ì—…
- [ ] DNS ì „í™˜
- [ ] ì• í”Œë¦¬ì¼€ì´ì…˜ í—¬ìŠ¤ì²´í¬

### ê²€ì¦
- [ ] API ì‘ë‹µ í™•ì¸
- [ ] ë°ì´í„° ì •í•©ì„± ê²€ì¦
- [ ] ì™¸ë¶€ ì—°ë™ í…ŒìŠ¤íŠ¸ (Popbill)
- [ ] ë¡œê·¸ì¸/ì¸ì¦ í…ŒìŠ¤íŠ¸
- [ ] íŠ¸ëœì­ì…˜ í…ŒìŠ¤íŠ¸

### ë³µêµ¬ (í›ˆë ¨ ì¢…ë£Œ)
- [ ] DNS ì›ë³µ
- [ ] DR í´ëŸ¬ìŠ¤í„° ìŠ¤ì¼€ì¼ë‹¤ìš´
- [ ] í›ˆë ¨ ê²°ê³¼ ë¬¸ì„œí™”
- [ ] ê°œì„ ì‚¬í•­ ë„ì¶œ

### í›ˆë ¨ ê²°ê³¼
- ì´ ì†Œìš” ì‹œê°„: ___ë¶„
- RTO ë‹¬ì„± ì—¬ë¶€: [ ] Yes / [ ] No
- ë°œê²¬ëœ ë¬¸ì œ: ___
- ê°œì„  í•„ìš”ì‚¬í•­: ___
```

## 8. ì—°ë½ë§ ë° ì—ìŠ¤ì»¬ë ˆì´ì…˜

### 8.1 ë¹„ìƒ ì—°ë½ë§
```yaml
emergency_contacts:
  level_1:  # ê²½ë¯¸
    - role: On-call Engineer
      contact: PagerDuty ìë™ í˜¸ì¶œ

  level_2:  # ë³´í†µ
    - role: DevOps Lead
      phone: 010-XXXX-XXXX
    - role: DBA
      phone: 010-XXXX-XXXX

  level_3:  # ì‹¬ê°
    - role: CTO
      phone: 010-XXXX-XXXX
    - role: VP Engineering
      phone: 010-XXXX-XXXX
    - role: Customer Success Lead
      phone: 010-XXXX-XXXX

  level_4:  # ì¹˜ëª…
    - role: CEO
      phone: 010-XXXX-XXXX
    - role: ë²•ë¬´íŒ€ì¥
      phone: 010-XXXX-XXXX
```

### 8.2 ì—ìŠ¤ì»¬ë ˆì´ì…˜ ë§¤íŠ¸ë¦­ìŠ¤
```
ì‹œê°„ ê²½ê³¼    â†’ 15ë¶„     â†’ 30ë¶„     â†’ 1ì‹œê°„    â†’ 2ì‹œê°„
Level 1     ìë™ë³µêµ¬    On-call    DevOps     -
Level 2     On-call    DevOps     CTO        CEO
Level 3     DevOps     CTO        CEO        ì™¸ë¶€ê³µì§€
Level 4     CTO+CEO    ì™¸ë¶€ê³µì§€   ê·œì œê¸°ê´€   ì–¸ë¡ ëŒ€ì‘
```

## 9. ê´€ë ¨ ë¬¸ì„œ

| ë¬¸ì„œ | ì„¤ëª… |
|------|------|
| [19_ë°°í¬_ìš´ì˜_ê°€ì´ë“œ.md](./19_ë°°í¬_ìš´ì˜_ê°€ì´ë“œ.md) | ë°°í¬ ë° ìš´ì˜ ì ˆì°¨ |
| [14_ëª¨ë‹ˆí„°ë§_ë¡œê¹…_ì „ëµ.md](./14_ëª¨ë‹ˆí„°ë§_ë¡œê¹…_ì „ëµ.md) | ëª¨ë‹ˆí„°ë§ ì„¤ì • |
| [07_ë³´ì•ˆ_ì„¤ê³„.md](./07_ë³´ì•ˆ_ì„¤ê³„.md) | ë³´ì•ˆ ì •ì±… |
| [21_ë°ì´í„°_ë§ˆì´ê·¸ë ˆì´ì…˜.md](./21_ë°ì´í„°_ë§ˆì´ê·¸ë ˆì´ì…˜.md) | ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜ |

---

*ë¬¸ì„œ ë²„ì „: 1.0.0*
*ìµœì¢… ìˆ˜ì •: 2025ë…„ 1ì›”*
*ì‘ì„±ì: K-ERP ê°œë°œíŒ€*
*ê²€í† : ì •ë³´ë³´ì•ˆíŒ€*
