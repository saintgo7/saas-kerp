# K-ERP 데이터 마이그레이션 가이드

## 목차

1. [개요](#1-개요)
2. [마이그레이션 전략](#2-마이그레이션-전략)
3. [데이터 매핑](#3-데이터-매핑)
4. [ETL 파이프라인](#4-etl-파이프라인)
5. [검증 및 품질 관리](#5-검증-및-품질-관리)
6. [롤백 전략](#6-롤백-전략)
7. [레거시 시스템별 가이드](#7-레거시-시스템별-가이드)
8. [마이그레이션 도구](#8-마이그레이션-도구)
9. [실행 체크리스트](#9-실행-체크리스트)
10. [문제 해결](#10-문제-해결)

---

## 1. 개요

### 1.1 마이그레이션 범위

```
┌─────────────────────────────────────────────────────────────────────────┐
│                      Data Migration Scope                                │
├─────────────────────────────────────────────────────────────────────────┤
│                                                                          │
│   Legacy Systems                        K-ERP                            │
│   ┌─────────────────┐                  ┌─────────────────┐              │
│   │ 기존 회계 S/W   │──────────────────│ 회계 모듈       │              │
│   │  - 계정과목     │   Transform &    │  - accounts     │              │
│   │  - 전표        │   Load           │  - vouchers     │              │
│   │  - 거래처      │                  │  - partners     │              │
│   └─────────────────┘                  └─────────────────┘              │
│                                                                          │
│   ┌─────────────────┐                  ┌─────────────────┐              │
│   │ Excel/CSV      │──────────────────│ 마스터 데이터    │              │
│   │  - 거래처목록   │   Validate &     │  - partners     │              │
│   │  - 품목목록    │   Import         │  - items        │              │
│   │  - 직원목록    │                  │  - employees    │              │
│   └─────────────────┘                  └─────────────────┘              │
│                                                                          │
│   ┌─────────────────┐                  ┌─────────────────┐              │
│   │ 인사급여 S/W   │──────────────────│ 인사급여 모듈    │              │
│   │  - 직원정보    │   Map &          │  - employees    │              │
│   │  - 급여대장    │   Transform      │  - payrolls     │              │
│   │  - 퇴직금     │                  │  - benefits     │              │
│   └─────────────────┘                  └─────────────────┘              │
│                                                                          │
│   ┌─────────────────┐                  ┌─────────────────┐              │
│   │ 세금계산서     │──────────────────│ 세금계산서 모듈  │              │
│   │  - 매출       │   Sync &         │  - invoices     │              │
│   │  - 매입       │   Reconcile      │  - ar/ap        │              │
│   └─────────────────┘                  └─────────────────┘              │
│                                                                          │
└─────────────────────────────────────────────────────────────────────────┘
```

### 1.2 마이그레이션 유형

| 유형 | 설명 | 대상 데이터 | 난이도 |
|------|------|-------------|--------|
| 마스터 이관 | 기준정보만 이관 | 계정과목, 거래처, 품목, 직원 | 하 |
| 기초잔액 이관 | 마스터 + 기초잔액 | 위 + 계정별 잔액 | 중 |
| 전체 이관 | 과거 전표까지 포함 | 위 + 전표, 세금계산서 | 상 |
| 증분 이관 | 운영 중 실시간 동기화 | 신규/변경 데이터 | 최상 |

### 1.3 마이그레이션 일정

| 단계 | 기간 | 활동 |
|------|------|------|
| 분석 | 1-2주 | 소스 시스템 분석, 매핑 정의 |
| 개발 | 2-3주 | ETL 스크립트 개발, 테스트 환경 구축 |
| 테스트 | 1-2주 | 테스트 마이그레이션, 검증 |
| 실행 | 1-2일 | 운영 마이그레이션 실행 |
| 검증 | 1주 | 데이터 정합성 검증, 이슈 해결 |

---

## 2. 마이그레이션 전략

### 2.1 Big Bang vs Phased Approach

```go
// internal/migration/strategy.go

package migration

import (
    "context"
    "time"
)

// MigrationStrategy defines the migration approach
type MigrationStrategy interface {
    Name() string
    Execute(ctx context.Context, config *MigrationConfig) error
    Rollback(ctx context.Context) error
}

// BigBangStrategy migrates all data at once during a maintenance window
type BigBangStrategy struct {
    sourceDB  Database
    targetDB  Database
    validator DataValidator
}

func (s *BigBangStrategy) Name() string {
    return "big-bang"
}

func (s *BigBangStrategy) Execute(ctx context.Context, config *MigrationConfig) error {
    // 1. Freeze source system
    if err := s.sourceDB.SetReadOnly(true); err != nil {
        return err
    }
    defer s.sourceDB.SetReadOnly(false)

    // 2. Extract all data
    data, err := s.extract(ctx, config)
    if err != nil {
        return err
    }

    // 3. Transform data
    transformed, err := s.transform(ctx, data, config.Mappings)
    if err != nil {
        return err
    }

    // 4. Load into target
    if err := s.load(ctx, transformed); err != nil {
        return err
    }

    // 5. Validate
    return s.validator.ValidateAll(ctx)
}

// PhasedStrategy migrates data in phases with parallel running
type PhasedStrategy struct {
    phases []MigrationPhase
}

type MigrationPhase struct {
    Name        string
    DataTypes   []string
    Order       int
    Parallel    bool
    DependsOn   []string
}

func (s *PhasedStrategy) Name() string {
    return "phased"
}

func (s *PhasedStrategy) Execute(ctx context.Context, config *MigrationConfig) error {
    for _, phase := range s.phases {
        select {
        case <-ctx.Done():
            return ctx.Err()
        default:
            if err := s.executePhase(ctx, phase, config); err != nil {
                return err
            }
        }
    }
    return nil
}

func (s *PhasedStrategy) executePhase(ctx context.Context, phase MigrationPhase, config *MigrationConfig) error {
    // Phase implementation
    return nil
}

// CDCStrategy uses Change Data Capture for minimal downtime
type CDCStrategy struct {
    sourceDB     Database
    targetDB     Database
    cdcConnector CDCConnector
    syncWindow   time.Duration
}

func (s *CDCStrategy) Name() string {
    return "cdc"
}

func (s *CDCStrategy) Execute(ctx context.Context, config *MigrationConfig) error {
    // 1. Initial bulk load
    if err := s.initialLoad(ctx, config); err != nil {
        return err
    }

    // 2. Start CDC streaming
    changes := s.cdcConnector.Stream(ctx, config.SourceTables)

    // 3. Apply changes until cutover
    for {
        select {
        case change := <-changes:
            if err := s.applyChange(ctx, change); err != nil {
                return err
            }
        case <-ctx.Done():
            return nil
        }
    }
}

func (s *CDCStrategy) initialLoad(ctx context.Context, config *MigrationConfig) error {
    return nil
}

func (s *CDCStrategy) applyChange(ctx context.Context, change Change) error {
    return nil
}
```

### 2.2 마이그레이션 설정

```yaml
# configs/migration/config.yaml

migration:
  name: "kerp-migration-2025"
  strategy: "phased"

  source:
    type: "mssql"
    host: "legacy-db.company.local"
    port: 1433
    database: "legacy_erp"
    username: "${LEGACY_DB_USER}"
    password: "${LEGACY_DB_PASS}"

  target:
    type: "postgresql"
    host: "${KERP_DB_HOST}"
    port: 5432
    database: "kerp"
    schema: "public"

  options:
    batch_size: 1000
    parallel_workers: 4
    error_threshold: 100
    validate_after_load: true
    create_audit_log: true

  phases:
    - name: "master_data"
      order: 1
      tables:
        - accounts
        - partners
        - items
        - employees
      parallel: true

    - name: "opening_balances"
      order: 2
      depends_on: ["master_data"]
      tables:
        - account_balances
      parallel: false

    - name: "transactions"
      order: 3
      depends_on: ["opening_balances"]
      tables:
        - vouchers
        - voucher_lines
        - invoices
      parallel: true
      date_filter:
        column: "created_at"
        from: "2024-01-01"

  mappings:
    file: "mappings/legacy_to_kerp.yaml"

  validation:
    rules:
      - type: "row_count"
        tolerance: 0
      - type: "checksum"
        columns: ["amount", "quantity"]
      - type: "referential_integrity"

  rollback:
    enabled: true
    backup_location: "s3://kerp-backups/migration/"
```

---

## 3. 데이터 매핑

### 3.1 계정과목 매핑

```yaml
# configs/migration/mappings/accounts.yaml

accounts:
  source_table: "GL_ACCOUNT"
  target_table: "accounts"

  columns:
    - source: "ACCT_CD"
      target: "code"
      transform: "trim"

    - source: "ACCT_NM"
      target: "name"
      transform: "trim"

    - source: "ACCT_TYPE"
      target: "account_type"
      transform: "map"
      mapping:
        "1": "asset"
        "2": "liability"
        "3": "equity"
        "4": "revenue"
        "5": "expense"

    - source: "PARENT_CD"
      target: "parent_code"
      transform: "trim"
      nullable: true

    - source: "IS_ACTIVE"
      target: "is_active"
      transform: "boolean"
      default: true

    - source: "USE_DEPT"
      target: "use_department"
      transform: "boolean"

    - source: "USE_PROJECT"
      target: "use_project"
      transform: "boolean"

  defaults:
    company_id: "${TARGET_COMPANY_ID}"
    is_system: false
    created_at: "NOW()"

  validation:
    - rule: "not_null"
      columns: ["code", "name", "account_type"]
    - rule: "unique"
      columns: ["company_id", "code"]
    - rule: "format"
      column: "code"
      pattern: "^[0-9]{4}$"
```

### 3.2 거래처 매핑

```yaml
# configs/migration/mappings/partners.yaml

partners:
  source_table: "BP_MASTER"
  target_table: "partners"

  columns:
    - source: "BP_CD"
      target: "code"
      transform: "trim"

    - source: "BP_NM"
      target: "name"
      transform: "trim"

    - source: "BIZ_NO"
      target: "business_number"
      transform: "format_business_number"

    - source: "REP_NM"
      target: "representative_name"
      transform: "trim"
      nullable: true

    - source: "BIZ_TYPE"
      target: "business_type"
      nullable: true

    - source: "BIZ_CATE"
      target: "business_category"
      nullable: true

    - source: "ADDR1"
      target: "address"
      transform: "concat"
      concat_with: ["ADDR2"]
      separator: " "

    - source: "TEL_NO"
      target: "phone"
      transform: "format_phone"
      nullable: true

    - source: "EMAIL"
      target: "email"
      transform: "lowercase"
      nullable: true

    - source: "BP_TYPE"
      target: "partner_type"
      transform: "map"
      mapping:
        "C": "customer"
        "V": "supplier"
        "B": "both"
      default: "both"

    - source: "IS_USE"
      target: "is_active"
      transform: "boolean_yn"

  custom_transforms:
    format_business_number: |
      def transform(value):
          if not value:
              return None
          # Remove all non-digits
          digits = ''.join(filter(str.isdigit, str(value)))
          if len(digits) == 10:
              return f"{digits[:3]}-{digits[3:5]}-{digits[5:]}"
          return value

    format_phone: |
      def transform(value):
          if not value:
              return None
          digits = ''.join(filter(str.isdigit, str(value)))
          if len(digits) == 11:
              return f"{digits[:3]}-{digits[3:7]}-{digits[7:]}"
          elif len(digits) == 10:
              return f"{digits[:2]}-{digits[2:6]}-{digits[6:]}"
          return value

  validation:
    - rule: "not_null"
      columns: ["code", "name"]
    - rule: "unique"
      columns: ["company_id", "code"]
    - rule: "business_number_checksum"
      column: "business_number"
      optional: true
```

### 3.3 전표 매핑

```yaml
# configs/migration/mappings/vouchers.yaml

vouchers:
  source_table: "GL_VOUCHER"
  target_table: "vouchers"

  columns:
    - source: "VOUCHER_NO"
      target: "voucher_number"

    - source: "VOUCHER_DT"
      target: "voucher_date"
      transform: "date"
      format: "YYYYMMDD"

    - source: "VOUCHER_TYPE"
      target: "voucher_type"
      transform: "map"
      mapping:
        "11": "general"
        "12": "cash_receipt"
        "13": "cash_payment"
        "21": "sales"
        "22": "purchase"
        "31": "adjustment"
        "99": "opening"
      default: "general"

    - source: "DESCRIPTION"
      target: "description"
      transform: "trim"

    - source: "STATUS"
      target: "status"
      transform: "map"
      mapping:
        "0": "draft"
        "1": "pending"
        "2": "approved"
        "9": "cancelled"

    - source: "TOTAL_DR"
      target: "total_debit"
      transform: "decimal_to_integer"

    - source: "TOTAL_CR"
      target: "total_credit"
      transform: "decimal_to_integer"

    - source: "CREATE_DT"
      target: "created_at"
      transform: "datetime"

    - source: "CREATE_USER"
      target: "created_by_legacy"
      # Will be mapped to user_id in post-processing

  children:
    voucher_lines:
      source_table: "GL_VOUCHER_LINE"
      foreign_key:
        source: "VOUCHER_NO"
        target: "voucher_id"
      columns:
        - source: "LINE_NO"
          target: "line_number"

        - source: "ACCT_CD"
          target: "account_code"
          # Will be resolved to account_id via lookup

        - source: "BP_CD"
          target: "partner_code"
          nullable: true

        - source: "DR_AMT"
          target: "debit_amount"
          transform: "decimal_to_integer"

        - source: "CR_AMT"
          target: "credit_amount"
          transform: "decimal_to_integer"

        - source: "DEPT_CD"
          target: "department_code"
          nullable: true

        - source: "REMARK"
          target: "description"
          nullable: true

voucher_lookups:
  - source_column: "account_code"
    target_column: "account_id"
    lookup_table: "accounts"
    lookup_key: "code"
    scope: "company_id"

  - source_column: "partner_code"
    target_column: "partner_id"
    lookup_table: "partners"
    lookup_key: "code"
    scope: "company_id"
    nullable: true
```

---

## 4. ETL 파이프라인

### 4.1 ETL 엔진

```go
// internal/migration/etl/engine.go

package etl

import (
    "context"
    "database/sql"
    "fmt"
    "sync"
    "time"

    "github.com/google/uuid"
    "kerp/pkg/logger"
)

type ETLEngine struct {
    sourceDB    *sql.DB
    targetDB    *sql.DB
    mappings    *MappingConfig
    transformer *Transformer
    validator   *Validator
    logger      *logger.Logger

    // Progress tracking
    progressMu  sync.RWMutex
    progress    map[string]*TableProgress
}

type TableProgress struct {
    TableName     string    `json:"table_name"`
    TotalRows     int64     `json:"total_rows"`
    ProcessedRows int64     `json:"processed_rows"`
    SuccessRows   int64     `json:"success_rows"`
    ErrorRows     int64     `json:"error_rows"`
    StartedAt     time.Time `json:"started_at"`
    CompletedAt   *time.Time `json:"completed_at,omitempty"`
    Status        string    `json:"status"` // pending, running, completed, failed
}

type ETLConfig struct {
    BatchSize       int
    ParallelWorkers int
    ErrorThreshold  int
    ValidateAfter   bool
    DryRun          bool
}

func NewETLEngine(sourceDB, targetDB *sql.DB, mappings *MappingConfig) *ETLEngine {
    return &ETLEngine{
        sourceDB:    sourceDB,
        targetDB:    targetDB,
        mappings:    mappings,
        transformer: NewTransformer(),
        validator:   NewValidator(),
        progress:    make(map[string]*TableProgress),
        logger:      logger.New("etl"),
    }
}

// Run executes the full ETL pipeline
func (e *ETLEngine) Run(ctx context.Context, config *ETLConfig) error {
    e.logger.Info("Starting ETL pipeline", "dry_run", config.DryRun)

    startTime := time.Now()

    // Process tables in order based on dependencies
    for _, tableMapping := range e.mappings.GetOrderedTables() {
        select {
        case <-ctx.Done():
            return ctx.Err()
        default:
            if err := e.processTable(ctx, tableMapping, config); err != nil {
                e.logger.Error("Table processing failed",
                    "table", tableMapping.TargetTable,
                    "error", err,
                )
                if !config.DryRun {
                    return fmt.Errorf("failed to process table %s: %w", tableMapping.TargetTable, err)
                }
            }
        }
    }

    // Post-processing: resolve lookups, update references
    if !config.DryRun {
        if err := e.postProcess(ctx); err != nil {
            return fmt.Errorf("post-processing failed: %w", err)
        }
    }

    // Validation
    if config.ValidateAfter && !config.DryRun {
        if err := e.validateAll(ctx); err != nil {
            return fmt.Errorf("validation failed: %w", err)
        }
    }

    e.logger.Info("ETL pipeline completed",
        "duration", time.Since(startTime),
        "tables_processed", len(e.mappings.GetOrderedTables()),
    )

    return nil
}

func (e *ETLEngine) processTable(ctx context.Context, mapping *TableMapping, config *ETLConfig) error {
    e.logger.Info("Processing table",
        "source", mapping.SourceTable,
        "target", mapping.TargetTable,
    )

    // Initialize progress
    e.initProgress(mapping.TargetTable)
    defer e.completeProgress(mapping.TargetTable)

    // Count source rows
    totalRows, err := e.countSourceRows(ctx, mapping)
    if err != nil {
        return err
    }
    e.updateProgress(mapping.TargetTable, func(p *TableProgress) {
        p.TotalRows = totalRows
        p.Status = "running"
    })

    // Extract in batches
    offset := 0
    errorCount := 0

    for {
        select {
        case <-ctx.Done():
            return ctx.Err()
        default:
        }

        // Extract batch
        rows, err := e.extractBatch(ctx, mapping, offset, config.BatchSize)
        if err != nil {
            return fmt.Errorf("extract failed at offset %d: %w", offset, err)
        }

        if len(rows) == 0 {
            break
        }

        // Transform batch
        transformed, transformErrors := e.transformBatch(ctx, mapping, rows)
        errorCount += len(transformErrors)

        // Log transform errors
        for _, te := range transformErrors {
            e.logger.Warn("Transform error",
                "table", mapping.TargetTable,
                "row", te.RowIndex,
                "error", te.Error,
            )
        }

        // Load batch (if not dry run)
        if !config.DryRun && len(transformed) > 0 {
            if err := e.loadBatch(ctx, mapping, transformed); err != nil {
                return fmt.Errorf("load failed at offset %d: %w", offset, err)
            }
        }

        // Update progress
        e.updateProgress(mapping.TargetTable, func(p *TableProgress) {
            p.ProcessedRows += int64(len(rows))
            p.SuccessRows += int64(len(transformed))
            p.ErrorRows += int64(len(transformErrors))
        })

        // Check error threshold
        if config.ErrorThreshold > 0 && errorCount >= config.ErrorThreshold {
            return fmt.Errorf("error threshold exceeded: %d errors", errorCount)
        }

        offset += config.BatchSize
    }

    e.logger.Info("Table processing completed",
        "table", mapping.TargetTable,
        "success", e.getProgress(mapping.TargetTable).SuccessRows,
        "errors", e.getProgress(mapping.TargetTable).ErrorRows,
    )

    return nil
}

func (e *ETLEngine) extractBatch(ctx context.Context, mapping *TableMapping, offset, limit int) ([]map[string]interface{}, error) {
    query := fmt.Sprintf(
        "SELECT * FROM %s ORDER BY %s OFFSET %d ROWS FETCH NEXT %d ROWS ONLY",
        mapping.SourceTable,
        mapping.GetPrimaryKey(),
        offset,
        limit,
    )

    rows, err := e.sourceDB.QueryContext(ctx, query)
    if err != nil {
        return nil, err
    }
    defer rows.Close()

    columns, err := rows.Columns()
    if err != nil {
        return nil, err
    }

    var result []map[string]interface{}

    for rows.Next() {
        values := make([]interface{}, len(columns))
        valuePtrs := make([]interface{}, len(columns))
        for i := range values {
            valuePtrs[i] = &values[i]
        }

        if err := rows.Scan(valuePtrs...); err != nil {
            return nil, err
        }

        row := make(map[string]interface{})
        for i, col := range columns {
            row[col] = values[i]
        }

        result = append(result, row)
    }

    return result, rows.Err()
}

type TransformError struct {
    RowIndex int
    Column   string
    Error    string
}

func (e *ETLEngine) transformBatch(ctx context.Context, mapping *TableMapping, rows []map[string]interface{}) ([]map[string]interface{}, []TransformError) {
    var transformed []map[string]interface{}
    var errors []TransformError

    for i, row := range rows {
        result, err := e.transformer.Transform(row, mapping)
        if err != nil {
            errors = append(errors, TransformError{
                RowIndex: i,
                Error:    err.Error(),
            })
            continue
        }

        // Apply defaults
        for key, value := range mapping.Defaults {
            if _, exists := result[key]; !exists {
                result[key] = e.resolveDefault(value)
            }
        }

        // Add system fields
        result["id"] = uuid.New()
        if _, hasCreatedAt := result["created_at"]; !hasCreatedAt {
            result["created_at"] = time.Now()
        }

        transformed = append(transformed, result)
    }

    return transformed, errors
}

func (e *ETLEngine) loadBatch(ctx context.Context, mapping *TableMapping, rows []map[string]interface{}) error {
    if len(rows) == 0 {
        return nil
    }

    // Build INSERT statement
    columns := make([]string, 0)
    for key := range rows[0] {
        columns = append(columns, key)
    }

    // Use COPY for PostgreSQL (much faster than INSERT)
    tx, err := e.targetDB.BeginTx(ctx, nil)
    if err != nil {
        return err
    }
    defer tx.Rollback()

    stmt, err := tx.PrepareContext(ctx, buildInsertStatement(mapping.TargetTable, columns))
    if err != nil {
        return err
    }
    defer stmt.Close()

    for _, row := range rows {
        values := make([]interface{}, len(columns))
        for i, col := range columns {
            values[i] = row[col]
        }

        if _, err := stmt.ExecContext(ctx, values...); err != nil {
            return fmt.Errorf("insert failed: %w", err)
        }
    }

    return tx.Commit()
}

func (e *ETLEngine) postProcess(ctx context.Context) error {
    e.logger.Info("Starting post-processing")

    // Resolve lookups (e.g., account_code -> account_id)
    for _, lookup := range e.mappings.Lookups {
        if err := e.resolveLookup(ctx, lookup); err != nil {
            return fmt.Errorf("failed to resolve lookup %s: %w", lookup.SourceColumn, err)
        }
    }

    // Update sequence values
    if err := e.updateSequences(ctx); err != nil {
        return fmt.Errorf("failed to update sequences: %w", err)
    }

    // Refresh materialized views
    if err := e.refreshViews(ctx); err != nil {
        return fmt.Errorf("failed to refresh views: %w", err)
    }

    return nil
}

func (e *ETLEngine) resolveLookup(ctx context.Context, lookup LookupConfig) error {
    query := fmt.Sprintf(`
        UPDATE %s t
        SET %s = l.id
        FROM %s l
        WHERE t.%s = l.%s
          AND t.company_id = l.company_id
          AND t.%s IS NOT NULL
    `,
        lookup.TargetTable,
        lookup.TargetColumn,
        lookup.LookupTable,
        lookup.SourceColumn,
        lookup.LookupKey,
        lookup.SourceColumn,
    )

    result, err := e.targetDB.ExecContext(ctx, query)
    if err != nil {
        return err
    }

    affected, _ := result.RowsAffected()
    e.logger.Info("Resolved lookup",
        "lookup", lookup.SourceColumn,
        "affected_rows", affected,
    )

    return nil
}

func (e *ETLEngine) validateAll(ctx context.Context) error {
    e.logger.Info("Running validation")

    for _, tableMapping := range e.mappings.GetOrderedTables() {
        if err := e.validator.ValidateTable(ctx, e.sourceDB, e.targetDB, tableMapping); err != nil {
            return err
        }
    }

    return nil
}

// Progress tracking helpers
func (e *ETLEngine) initProgress(table string) {
    e.progressMu.Lock()
    defer e.progressMu.Unlock()

    e.progress[table] = &TableProgress{
        TableName: table,
        StartedAt: time.Now(),
        Status:    "pending",
    }
}

func (e *ETLEngine) updateProgress(table string, fn func(*TableProgress)) {
    e.progressMu.Lock()
    defer e.progressMu.Unlock()

    if p, ok := e.progress[table]; ok {
        fn(p)
    }
}

func (e *ETLEngine) completeProgress(table string) {
    e.progressMu.Lock()
    defer e.progressMu.Unlock()

    if p, ok := e.progress[table]; ok {
        now := time.Now()
        p.CompletedAt = &now
        if p.ErrorRows > 0 {
            p.Status = "completed_with_errors"
        } else {
            p.Status = "completed"
        }
    }
}

func (e *ETLEngine) getProgress(table string) *TableProgress {
    e.progressMu.RLock()
    defer e.progressMu.RUnlock()
    return e.progress[table]
}

func (e *ETLEngine) GetAllProgress() map[string]*TableProgress {
    e.progressMu.RLock()
    defer e.progressMu.RUnlock()

    result := make(map[string]*TableProgress)
    for k, v := range e.progress {
        result[k] = v
    }
    return result
}

// Helper functions
func buildInsertStatement(table string, columns []string) string {
    placeholders := make([]string, len(columns))
    for i := range columns {
        placeholders[i] = fmt.Sprintf("$%d", i+1)
    }

    return fmt.Sprintf(
        "INSERT INTO %s (%s) VALUES (%s)",
        table,
        strings.Join(columns, ", "),
        strings.Join(placeholders, ", "),
    )
}

func (e *ETLEngine) resolveDefault(value string) interface{} {
    switch value {
    case "NOW()":
        return time.Now()
    case "UUID()":
        return uuid.New()
    default:
        // Check for environment variable reference
        if strings.HasPrefix(value, "${") && strings.HasSuffix(value, "}") {
            envVar := value[2 : len(value)-1]
            return os.Getenv(envVar)
        }
        return value
    }
}

func (e *ETLEngine) countSourceRows(ctx context.Context, mapping *TableMapping) (int64, error) {
    var count int64
    query := fmt.Sprintf("SELECT COUNT(*) FROM %s", mapping.SourceTable)

    if mapping.Filter != "" {
        query += " WHERE " + mapping.Filter
    }

    err := e.sourceDB.QueryRowContext(ctx, query).Scan(&count)
    return count, err
}

func (e *ETLEngine) updateSequences(ctx context.Context) error {
    // Update PostgreSQL sequences based on max ID values
    query := `
        SELECT setval(pg_get_serial_sequence(table_name, 'id'),
               COALESCE(MAX(id)::bigint, 1),
               MAX(id) IS NOT NULL)
        FROM (
            SELECT 'vouchers' as table_name, MAX(voucher_number::bigint) as id FROM vouchers
            UNION ALL
            SELECT 'invoices', MAX(invoice_number::bigint) FROM invoices
        ) t
        GROUP BY table_name
    `
    _, err := e.targetDB.ExecContext(ctx, query)
    return err
}

func (e *ETLEngine) refreshViews(ctx context.Context) error {
    views := []string{
        "mv_account_balances",
        "mv_partner_summaries",
    }

    for _, view := range views {
        _, err := e.targetDB.ExecContext(ctx,
            fmt.Sprintf("REFRESH MATERIALIZED VIEW CONCURRENTLY %s", view))
        if err != nil {
            // Views might not exist, just log warning
            e.logger.Warn("Failed to refresh view", "view", view, "error", err)
        }
    }

    return nil
}
```

### 4.2 데이터 변환기

```go
// internal/migration/etl/transformer.go

package etl

import (
    "fmt"
    "regexp"
    "strconv"
    "strings"
    "time"
)

type Transformer struct {
    customFunctions map[string]TransformFunc
}

type TransformFunc func(value interface{}) (interface{}, error)

func NewTransformer() *Transformer {
    t := &Transformer{
        customFunctions: make(map[string]TransformFunc),
    }
    t.registerBuiltins()
    return t
}

func (t *Transformer) registerBuiltins() {
    // String transforms
    t.customFunctions["trim"] = func(v interface{}) (interface{}, error) {
        if v == nil {
            return nil, nil
        }
        return strings.TrimSpace(fmt.Sprintf("%v", v)), nil
    }

    t.customFunctions["lowercase"] = func(v interface{}) (interface{}, error) {
        if v == nil {
            return nil, nil
        }
        return strings.ToLower(fmt.Sprintf("%v", v)), nil
    }

    t.customFunctions["uppercase"] = func(v interface{}) (interface{}, error) {
        if v == nil {
            return nil, nil
        }
        return strings.ToUpper(fmt.Sprintf("%v", v)), nil
    }

    // Boolean transforms
    t.customFunctions["boolean"] = func(v interface{}) (interface{}, error) {
        if v == nil {
            return false, nil
        }
        switch val := v.(type) {
        case bool:
            return val, nil
        case int, int64:
            return val != 0, nil
        case string:
            return strings.ToLower(val) == "true" || val == "1", nil
        }
        return false, nil
    }

    t.customFunctions["boolean_yn"] = func(v interface{}) (interface{}, error) {
        if v == nil {
            return false, nil
        }
        str := strings.ToUpper(fmt.Sprintf("%v", v))
        return str == "Y" || str == "YES", nil
    }

    // Number transforms
    t.customFunctions["decimal_to_integer"] = func(v interface{}) (interface{}, error) {
        if v == nil {
            return int64(0), nil
        }
        switch val := v.(type) {
        case float64:
            return int64(val), nil
        case float32:
            return int64(val), nil
        case int64:
            return val, nil
        case int:
            return int64(val), nil
        case string:
            f, err := strconv.ParseFloat(strings.ReplaceAll(val, ",", ""), 64)
            if err != nil {
                return nil, err
            }
            return int64(f), nil
        }
        return int64(0), nil
    }

    // Date transforms
    t.customFunctions["date"] = func(v interface{}) (interface{}, error) {
        if v == nil {
            return nil, nil
        }

        var dateStr string
        switch val := v.(type) {
        case time.Time:
            return val, nil
        case string:
            dateStr = val
        default:
            dateStr = fmt.Sprintf("%v", v)
        }

        // Try common formats
        formats := []string{
            "20060102",           // YYYYMMDD
            "2006-01-02",         // YYYY-MM-DD
            "2006/01/02",         // YYYY/MM/DD
            "02-01-2006",         // DD-MM-YYYY
            "01/02/2006",         // MM/DD/YYYY
            time.RFC3339,
        }

        for _, format := range formats {
            if t, err := time.Parse(format, dateStr); err == nil {
                return t, nil
            }
        }

        return nil, fmt.Errorf("unable to parse date: %s", dateStr)
    }

    t.customFunctions["datetime"] = func(v interface{}) (interface{}, error) {
        if v == nil {
            return nil, nil
        }

        switch val := v.(type) {
        case time.Time:
            return val, nil
        case string:
            formats := []string{
                "20060102150405",           // YYYYMMDDHHmmss
                "2006-01-02 15:04:05",      // YYYY-MM-DD HH:mm:ss
                "2006-01-02T15:04:05",      // ISO 8601
                time.RFC3339,
            }

            for _, format := range formats {
                if t, err := time.Parse(format, val); err == nil {
                    return t, nil
                }
            }
        }

        return nil, fmt.Errorf("unable to parse datetime: %v", v)
    }

    // Business number format
    t.customFunctions["format_business_number"] = func(v interface{}) (interface{}, error) {
        if v == nil {
            return nil, nil
        }

        str := fmt.Sprintf("%v", v)
        // Remove all non-digits
        re := regexp.MustCompile(`[^0-9]`)
        digits := re.ReplaceAllString(str, "")

        if len(digits) != 10 {
            return str, nil // Return as-is if not valid length
        }

        return fmt.Sprintf("%s-%s-%s", digits[:3], digits[3:5], digits[5:]), nil
    }
}

// Transform applies mapping transformations to a source row
func (t *Transformer) Transform(row map[string]interface{}, mapping *TableMapping) (map[string]interface{}, error) {
    result := make(map[string]interface{})

    for _, colMapping := range mapping.Columns {
        sourceValue := row[colMapping.Source]

        // Handle nullable columns
        if sourceValue == nil {
            if colMapping.Nullable {
                if colMapping.Default != nil {
                    result[colMapping.Target] = colMapping.Default
                }
                continue
            } else {
                return nil, fmt.Errorf("null value for non-nullable column: %s", colMapping.Target)
            }
        }

        // Apply transformation
        var transformedValue interface{}
        var err error

        switch colMapping.Transform {
        case "map":
            transformedValue, err = t.applyMapping(sourceValue, colMapping.Mapping, colMapping.Default)
        case "concat":
            transformedValue, err = t.applyConcat(row, colMapping.ConcatWith, colMapping.Separator)
        case "":
            transformedValue = sourceValue
        default:
            if fn, ok := t.customFunctions[colMapping.Transform]; ok {
                transformedValue, err = fn(sourceValue)
            } else {
                err = fmt.Errorf("unknown transform: %s", colMapping.Transform)
            }
        }

        if err != nil {
            return nil, fmt.Errorf("transform failed for column %s: %w", colMapping.Target, err)
        }

        result[colMapping.Target] = transformedValue
    }

    return result, nil
}

func (t *Transformer) applyMapping(value interface{}, mapping map[string]string, defaultValue interface{}) (interface{}, error) {
    key := fmt.Sprintf("%v", value)

    if mapped, ok := mapping[key]; ok {
        return mapped, nil
    }

    if defaultValue != nil {
        return defaultValue, nil
    }

    return value, nil
}

func (t *Transformer) applyConcat(row map[string]interface{}, columns []string, separator string) (interface{}, error) {
    var parts []string

    for _, col := range columns {
        if val, ok := row[col]; ok && val != nil {
            parts = append(parts, fmt.Sprintf("%v", val))
        }
    }

    return strings.Join(parts, separator), nil
}

// RegisterCustomFunction adds a custom transformation function
func (t *Transformer) RegisterCustomFunction(name string, fn TransformFunc) {
    t.customFunctions[name] = fn
}
```

---

## 5. 검증 및 품질 관리

### 5.1 데이터 검증기

```go
// internal/migration/etl/validator.go

package etl

import (
    "context"
    "database/sql"
    "fmt"

    "kerp/pkg/logger"
)

type Validator struct {
    logger *logger.Logger
}

func NewValidator() *Validator {
    return &Validator{
        logger: logger.New("validator"),
    }
}

// ValidateTable performs comprehensive validation on a migrated table
func (v *Validator) ValidateTable(ctx context.Context, sourceDB, targetDB *sql.DB, mapping *TableMapping) error {
    v.logger.Info("Validating table", "table", mapping.TargetTable)

    // 1. Row count validation
    if err := v.validateRowCount(ctx, sourceDB, targetDB, mapping); err != nil {
        return fmt.Errorf("row count validation failed: %w", err)
    }

    // 2. Checksum validation for numeric columns
    if err := v.validateChecksums(ctx, sourceDB, targetDB, mapping); err != nil {
        return fmt.Errorf("checksum validation failed: %w", err)
    }

    // 3. Referential integrity
    if err := v.validateReferentialIntegrity(ctx, targetDB, mapping); err != nil {
        return fmt.Errorf("referential integrity validation failed: %w", err)
    }

    // 4. Business rules
    if err := v.validateBusinessRules(ctx, targetDB, mapping); err != nil {
        return fmt.Errorf("business rule validation failed: %w", err)
    }

    v.logger.Info("Table validation passed", "table", mapping.TargetTable)
    return nil
}

func (v *Validator) validateRowCount(ctx context.Context, sourceDB, targetDB *sql.DB, mapping *TableMapping) error {
    var sourceCount, targetCount int64

    // Count source
    sourceQuery := fmt.Sprintf("SELECT COUNT(*) FROM %s", mapping.SourceTable)
    if mapping.Filter != "" {
        sourceQuery += " WHERE " + mapping.Filter
    }
    if err := sourceDB.QueryRowContext(ctx, sourceQuery).Scan(&sourceCount); err != nil {
        return err
    }

    // Count target
    targetQuery := fmt.Sprintf("SELECT COUNT(*) FROM %s", mapping.TargetTable)
    if mapping.TargetFilter != "" {
        targetQuery += " WHERE " + mapping.TargetFilter
    }
    if err := targetDB.QueryRowContext(ctx, targetQuery).Scan(&targetCount); err != nil {
        return err
    }

    v.logger.Info("Row count comparison",
        "source", sourceCount,
        "target", targetCount,
        "table", mapping.TargetTable,
    )

    if sourceCount != targetCount {
        return fmt.Errorf("row count mismatch: source=%d, target=%d", sourceCount, targetCount)
    }

    return nil
}

func (v *Validator) validateChecksums(ctx context.Context, sourceDB, targetDB *sql.DB, mapping *TableMapping) error {
    // Get numeric columns from mapping
    numericColumns := make([]string, 0)
    for _, col := range mapping.Columns {
        if col.Type == "numeric" || col.Type == "decimal" || col.Type == "integer" {
            numericColumns = append(numericColumns, col.Target)
        }
    }

    if len(numericColumns) == 0 {
        return nil
    }

    for _, col := range numericColumns {
        sourceCol := mapping.GetSourceColumn(col)

        var sourceSum, targetSum sql.NullFloat64

        // Source sum
        sourceQuery := fmt.Sprintf("SELECT SUM(CAST(%s AS DECIMAL(20,2))) FROM %s", sourceCol, mapping.SourceTable)
        if mapping.Filter != "" {
            sourceQuery += " WHERE " + mapping.Filter
        }
        if err := sourceDB.QueryRowContext(ctx, sourceQuery).Scan(&sourceSum); err != nil {
            return fmt.Errorf("failed to get source sum for %s: %w", col, err)
        }

        // Target sum
        targetQuery := fmt.Sprintf("SELECT SUM(%s) FROM %s", col, mapping.TargetTable)
        if mapping.TargetFilter != "" {
            targetQuery += " WHERE " + mapping.TargetFilter
        }
        if err := targetDB.QueryRowContext(ctx, targetQuery).Scan(&targetSum); err != nil {
            return fmt.Errorf("failed to get target sum for %s: %w", col, err)
        }

        // Compare
        sourceSumVal := 0.0
        targetSumVal := 0.0
        if sourceSum.Valid {
            sourceSumVal = sourceSum.Float64
        }
        if targetSum.Valid {
            targetSumVal = targetSum.Float64
        }

        // Allow small tolerance for floating point comparison
        diff := sourceSumVal - targetSumVal
        if diff < 0 {
            diff = -diff
        }

        if diff > 0.01 {
            return fmt.Errorf("checksum mismatch for %s: source=%.2f, target=%.2f", col, sourceSumVal, targetSumVal)
        }

        v.logger.Info("Checksum validated",
            "column", col,
            "source_sum", sourceSumVal,
            "target_sum", targetSumVal,
        )
    }

    return nil
}

func (v *Validator) validateReferentialIntegrity(ctx context.Context, targetDB *sql.DB, mapping *TableMapping) error {
    // Check foreign key references
    for _, fk := range mapping.ForeignKeys {
        query := fmt.Sprintf(`
            SELECT COUNT(*)
            FROM %s t
            LEFT JOIN %s r ON t.%s = r.%s
            WHERE t.%s IS NOT NULL AND r.%s IS NULL
        `,
            mapping.TargetTable,
            fk.ReferenceTable,
            fk.Column,
            fk.ReferenceColumn,
            fk.Column,
            fk.ReferenceColumn,
        )

        var orphanCount int64
        if err := targetDB.QueryRowContext(ctx, query).Scan(&orphanCount); err != nil {
            return fmt.Errorf("failed to check FK %s: %w", fk.Column, err)
        }

        if orphanCount > 0 {
            return fmt.Errorf("orphan records found for FK %s: %d records", fk.Column, orphanCount)
        }

        v.logger.Info("FK validation passed",
            "column", fk.Column,
            "reference", fk.ReferenceTable,
        )
    }

    return nil
}

func (v *Validator) validateBusinessRules(ctx context.Context, targetDB *sql.DB, mapping *TableMapping) error {
    // Table-specific business rules
    switch mapping.TargetTable {
    case "vouchers":
        return v.validateVoucherBalances(ctx, targetDB)
    case "account_balances":
        return v.validateAccountBalances(ctx, targetDB)
    }

    return nil
}

func (v *Validator) validateVoucherBalances(ctx context.Context, targetDB *sql.DB) error {
    // Check that all vouchers are balanced (debit = credit)
    query := `
        SELECT id, voucher_number, total_debit, total_credit
        FROM vouchers
        WHERE total_debit != total_credit
    `

    rows, err := targetDB.QueryContext(ctx, query)
    if err != nil {
        return err
    }
    defer rows.Close()

    unbalancedCount := 0
    for rows.Next() {
        var id, voucherNumber string
        var debit, credit int64
        if err := rows.Scan(&id, &voucherNumber, &debit, &credit); err != nil {
            return err
        }

        v.logger.Warn("Unbalanced voucher found",
            "voucher_number", voucherNumber,
            "debit", debit,
            "credit", credit,
        )
        unbalancedCount++
    }

    if unbalancedCount > 0 {
        return fmt.Errorf("found %d unbalanced vouchers", unbalancedCount)
    }

    return nil
}

func (v *Validator) validateAccountBalances(ctx context.Context, targetDB *sql.DB) error {
    // Check that trial balance is balanced
    query := `
        SELECT
            SUM(CASE WHEN account_type IN ('asset', 'expense') THEN balance ELSE 0 END) as debit_total,
            SUM(CASE WHEN account_type IN ('liability', 'equity', 'revenue') THEN balance ELSE 0 END) as credit_total
        FROM account_balances ab
        JOIN accounts a ON ab.account_id = a.id
    `

    var debitTotal, creditTotal sql.NullInt64
    if err := targetDB.QueryRowContext(ctx, query).Scan(&debitTotal, &creditTotal); err != nil {
        return err
    }

    debit := int64(0)
    credit := int64(0)
    if debitTotal.Valid {
        debit = debitTotal.Int64
    }
    if creditTotal.Valid {
        credit = creditTotal.Int64
    }

    if debit != credit {
        return fmt.Errorf("trial balance not balanced: debit=%d, credit=%d", debit, credit)
    }

    v.logger.Info("Trial balance validated", "total", debit)

    return nil
}

// ValidationReport holds all validation results
type ValidationReport struct {
    TableReports []TableValidationReport `json:"table_reports"`
    Summary      ValidationSummary       `json:"summary"`
}

type TableValidationReport struct {
    TableName    string            `json:"table_name"`
    RowCount     RowCountResult    `json:"row_count"`
    Checksums    []ChecksumResult  `json:"checksums"`
    ForeignKeys  []FKResult        `json:"foreign_keys"`
    BusinessRules []RuleResult     `json:"business_rules"`
    Status       string            `json:"status"`
}

type RowCountResult struct {
    SourceCount int64 `json:"source_count"`
    TargetCount int64 `json:"target_count"`
    Match       bool  `json:"match"`
}

type ChecksumResult struct {
    Column     string  `json:"column"`
    SourceSum  float64 `json:"source_sum"`
    TargetSum  float64 `json:"target_sum"`
    Difference float64 `json:"difference"`
    Valid      bool    `json:"valid"`
}

type FKResult struct {
    Column        string `json:"column"`
    ReferenceTable string `json:"reference_table"`
    OrphanCount   int64  `json:"orphan_count"`
    Valid         bool   `json:"valid"`
}

type RuleResult struct {
    Rule   string `json:"rule"`
    Valid  bool   `json:"valid"`
    Detail string `json:"detail,omitempty"`
}

type ValidationSummary struct {
    TotalTables   int  `json:"total_tables"`
    PassedTables  int  `json:"passed_tables"`
    FailedTables  int  `json:"failed_tables"`
    AllPassed     bool `json:"all_passed"`
}

// GenerateReport creates a comprehensive validation report
func (v *Validator) GenerateReport(ctx context.Context, sourceDB, targetDB *sql.DB, mappings *MappingConfig) (*ValidationReport, error) {
    report := &ValidationReport{
        TableReports: make([]TableValidationReport, 0),
    }

    for _, mapping := range mappings.GetOrderedTables() {
        tableReport := TableValidationReport{
            TableName: mapping.TargetTable,
        }

        // Perform validations and collect results
        // ... implementation details

        report.TableReports = append(report.TableReports, tableReport)
    }

    // Calculate summary
    for _, tr := range report.TableReports {
        report.Summary.TotalTables++
        if tr.Status == "passed" {
            report.Summary.PassedTables++
        } else {
            report.Summary.FailedTables++
        }
    }
    report.Summary.AllPassed = report.Summary.FailedTables == 0

    return report, nil
}
```

---

## 6. 롤백 전략

### 6.1 롤백 매니저

```go
// internal/migration/rollback.go

package migration

import (
    "context"
    "database/sql"
    "fmt"
    "io"
    "os"
    "time"

    "kerp/pkg/logger"
)

type RollbackManager struct {
    db             *sql.DB
    backupLocation string
    logger         *logger.Logger
}

type BackupMetadata struct {
    ID          string    `json:"id"`
    CreatedAt   time.Time `json:"created_at"`
    Tables      []string  `json:"tables"`
    CompanyID   string    `json:"company_id"`
    Size        int64     `json:"size"`
    Status      string    `json:"status"`
    Description string    `json:"description"`
}

func NewRollbackManager(db *sql.DB, backupLocation string) *RollbackManager {
    return &RollbackManager{
        db:             db,
        backupLocation: backupLocation,
        logger:         logger.New("rollback"),
    }
}

// CreateBackup creates a backup before migration
func (rm *RollbackManager) CreateBackup(ctx context.Context, companyID string, tables []string, description string) (*BackupMetadata, error) {
    rm.logger.Info("Creating backup", "company_id", companyID, "tables", tables)

    backupID := fmt.Sprintf("backup_%s_%d", companyID, time.Now().Unix())
    backupPath := fmt.Sprintf("%s/%s", rm.backupLocation, backupID)

    if err := os.MkdirAll(backupPath, 0755); err != nil {
        return nil, fmt.Errorf("failed to create backup directory: %w", err)
    }

    metadata := &BackupMetadata{
        ID:          backupID,
        CreatedAt:   time.Now(),
        Tables:      tables,
        CompanyID:   companyID,
        Status:      "in_progress",
        Description: description,
    }

    var totalSize int64

    for _, table := range tables {
        // Export table to file
        filePath := fmt.Sprintf("%s/%s.csv", backupPath, table)
        size, err := rm.exportTable(ctx, table, companyID, filePath)
        if err != nil {
            rm.logger.Error("Failed to backup table", "table", table, "error", err)
            metadata.Status = "failed"
            return metadata, err
        }
        totalSize += size
        rm.logger.Info("Table backed up", "table", table, "size", size)
    }

    metadata.Size = totalSize
    metadata.Status = "completed"

    // Save metadata
    if err := rm.saveMetadata(backupPath, metadata); err != nil {
        return nil, err
    }

    rm.logger.Info("Backup completed", "backup_id", backupID, "total_size", totalSize)

    return metadata, nil
}

func (rm *RollbackManager) exportTable(ctx context.Context, table, companyID, filePath string) (int64, error) {
    file, err := os.Create(filePath)
    if err != nil {
        return 0, err
    }
    defer file.Close()

    query := fmt.Sprintf(
        "COPY (SELECT * FROM %s WHERE company_id = $1) TO STDOUT WITH CSV HEADER",
        table,
    )

    rows, err := rm.db.QueryContext(ctx, query, companyID)
    if err != nil {
        return 0, err
    }
    defer rows.Close()

    // Write rows to file
    written, err := rm.writeRowsToCSV(rows, file)
    if err != nil {
        return 0, err
    }

    return written, nil
}

func (rm *RollbackManager) writeRowsToCSV(rows *sql.Rows, w io.Writer) (int64, error) {
    columns, err := rows.Columns()
    if err != nil {
        return 0, err
    }

    // Write header
    header := strings.Join(columns, ",") + "\n"
    written := int64(len(header))
    if _, err := w.Write([]byte(header)); err != nil {
        return written, err
    }

    values := make([]interface{}, len(columns))
    valuePtrs := make([]interface{}, len(columns))
    for i := range values {
        valuePtrs[i] = &values[i]
    }

    for rows.Next() {
        if err := rows.Scan(valuePtrs...); err != nil {
            return written, err
        }

        // Build CSV line
        line := make([]string, len(columns))
        for i, v := range values {
            if v == nil {
                line[i] = ""
            } else {
                line[i] = fmt.Sprintf("%v", v)
            }
        }

        csvLine := strings.Join(line, ",") + "\n"
        written += int64(len(csvLine))
        if _, err := w.Write([]byte(csvLine)); err != nil {
            return written, err
        }
    }

    return written, rows.Err()
}

// Rollback restores data from a backup
func (rm *RollbackManager) Rollback(ctx context.Context, backupID string) error {
    rm.logger.Info("Starting rollback", "backup_id", backupID)

    backupPath := fmt.Sprintf("%s/%s", rm.backupLocation, backupID)

    // Load metadata
    metadata, err := rm.loadMetadata(backupPath)
    if err != nil {
        return fmt.Errorf("failed to load backup metadata: %w", err)
    }

    // Begin transaction
    tx, err := rm.db.BeginTx(ctx, nil)
    if err != nil {
        return err
    }
    defer tx.Rollback()

    // Delete migrated data first
    for _, table := range metadata.Tables {
        deleteQuery := fmt.Sprintf("DELETE FROM %s WHERE company_id = $1", table)
        if _, err := tx.ExecContext(ctx, deleteQuery, metadata.CompanyID); err != nil {
            return fmt.Errorf("failed to delete from %s: %w", table, err)
        }
        rm.logger.Info("Deleted migrated data", "table", table)
    }

    // Restore from backup
    for _, table := range metadata.Tables {
        filePath := fmt.Sprintf("%s/%s.csv", backupPath, table)
        if err := rm.importTable(ctx, tx, table, filePath); err != nil {
            return fmt.Errorf("failed to restore %s: %w", table, err)
        }
        rm.logger.Info("Table restored", "table", table)
    }

    if err := tx.Commit(); err != nil {
        return fmt.Errorf("failed to commit rollback: %w", err)
    }

    rm.logger.Info("Rollback completed", "backup_id", backupID)

    return nil
}

func (rm *RollbackManager) importTable(ctx context.Context, tx *sql.Tx, table, filePath string) error {
    file, err := os.Open(filePath)
    if err != nil {
        return err
    }
    defer file.Close()

    // Use COPY FROM for PostgreSQL
    query := fmt.Sprintf("COPY %s FROM STDIN WITH CSV HEADER", table)

    _, err = tx.ExecContext(ctx, query)
    // Note: This is simplified. Real implementation would need to pipe the file content

    return err
}

func (rm *RollbackManager) saveMetadata(backupPath string, metadata *BackupMetadata) error {
    // Save metadata to JSON file
    return nil
}

func (rm *RollbackManager) loadMetadata(backupPath string) (*BackupMetadata, error) {
    // Load metadata from JSON file
    return nil, nil
}

// ListBackups returns available backups
func (rm *RollbackManager) ListBackups(ctx context.Context, companyID string) ([]BackupMetadata, error) {
    // List backup directories and load their metadata
    return nil, nil
}

// DeleteBackup removes a backup
func (rm *RollbackManager) DeleteBackup(ctx context.Context, backupID string) error {
    backupPath := fmt.Sprintf("%s/%s", rm.backupLocation, backupID)
    return os.RemoveAll(backupPath)
}
```

---

## 7. 레거시 시스템별 가이드

### 7.1 더존 ERP 마이그레이션

```yaml
# configs/migration/legacy/douzone.yaml

source:
  system: "douzone"
  database: "mssql"

table_mappings:
  # 계정과목
  accounts:
    source: "CM_ACNT"
    query: |
      SELECT
        ACNT_CD as code,
        ACNT_NM as name,
        ACNT_TP as account_type,
        PRNT_CD as parent_code,
        USE_YN as is_active
      FROM CM_ACNT
      WHERE COMP_CD = :company_code

  # 거래처
  partners:
    source: "CM_CUST"
    query: |
      SELECT
        CUST_CD as code,
        CUST_NM as name,
        BIZR_NO as business_number,
        CEO_NM as representative_name,
        BSNS_COND as business_type,
        BCLS_NM as business_category,
        ADDR as address,
        TEL_NO as phone,
        EMAIL as email,
        CASE CUST_TP
          WHEN '1' THEN 'customer'
          WHEN '2' THEN 'supplier'
          ELSE 'both'
        END as partner_type
      FROM CM_CUST
      WHERE COMP_CD = :company_code
        AND USE_YN = 'Y'

  # 전표
  vouchers:
    source: "GL_SLIP"
    query: |
      SELECT
        SLIP_NO as voucher_number,
        CONVERT(DATE, SLIP_DT) as voucher_date,
        SLIP_TP as voucher_type,
        RMRK as description,
        CASE APPR_YN
          WHEN 'Y' THEN 'approved'
          ELSE 'draft'
        END as status,
        REG_DT as created_at,
        REG_ID as created_by
      FROM GL_SLIP
      WHERE COMP_CD = :company_code
        AND SLIP_YY >= :fiscal_year

  # 전표 상세
  voucher_lines:
    source: "GL_SLIP_DTL"
    query: |
      SELECT
        SLIP_NO as voucher_number,
        SEQ_NO as line_number,
        ACNT_CD as account_code,
        CUST_CD as partner_code,
        DEPT_CD as department_code,
        DR_AMT as debit_amount,
        CR_AMT as credit_amount,
        RMRK as description
      FROM GL_SLIP_DTL
      WHERE COMP_CD = :company_code
        AND SLIP_YY >= :fiscal_year

type_mappings:
  voucher_type:
    "11": "general"
    "12": "cash_receipt"
    "13": "cash_payment"
    "21": "sales"
    "22": "purchase"

post_processing:
  - resolve_account_ids
  - resolve_partner_ids
  - validate_voucher_balances
```

### 7.2 세무사 프로그램 마이그레이션

```yaml
# configs/migration/legacy/taxsoft.yaml

source:
  system: "generic_taxsoft"
  format: "excel"

file_mappings:
  # 계정과목 (계정과목표.xlsx)
  accounts:
    sheet: "계정과목"
    header_row: 1
    columns:
      A: code          # 계정코드
      B: name          # 계정명
      C: account_type  # 계정구분 (자산/부채/자본/수익/비용)
      D: parent_code   # 상위계정

  # 거래처 (거래처관리.xlsx)
  partners:
    sheet: "거래처목록"
    header_row: 1
    columns:
      A: code
      B: name
      C: business_number
      D: representative_name
      E: address
      F: phone
      G: email

  # 기초잔액 (기초잔액.xlsx)
  opening_balances:
    sheet: "시산표"
    header_row: 2
    columns:
      A: account_code
      B: account_name   # 참조용
      C: debit_balance
      D: credit_balance

  # 매입매출장 (매입매출장.xlsx)
  tax_invoices:
    sheet: "매입매출"
    header_row: 1
    columns:
      A: invoice_date
      B: invoice_number
      C: type           # 매출/매입
      D: partner_code
      E: partner_name
      F: partner_business_number
      G: supply_amount
      H: tax_amount
      I: total_amount
      J: description
```

---

## 8. 마이그레이션 도구

### 8.1 CLI 도구

```go
// cmd/migrate/main.go

package main

import (
    "context"
    "fmt"
    "os"
    "os/signal"
    "syscall"

    "github.com/spf13/cobra"
    "kerp/internal/migration"
    "kerp/internal/migration/etl"
)

var rootCmd = &cobra.Command{
    Use:   "kerp-migrate",
    Short: "K-ERP Data Migration Tool",
    Long:  "A comprehensive data migration tool for migrating data from legacy systems to K-ERP.",
}

var runCmd = &cobra.Command{
    Use:   "run",
    Short: "Run migration",
    RunE: func(cmd *cobra.Command, args []string) error {
        configFile, _ := cmd.Flags().GetString("config")
        dryRun, _ := cmd.Flags().GetBool("dry-run")

        ctx, cancel := context.WithCancel(context.Background())
        defer cancel()

        // Handle graceful shutdown
        sigChan := make(chan os.Signal, 1)
        signal.Notify(sigChan, syscall.SIGINT, syscall.SIGTERM)
        go func() {
            <-sigChan
            fmt.Println("\nReceived shutdown signal, canceling migration...")
            cancel()
        }()

        // Load configuration
        config, err := migration.LoadConfig(configFile)
        if err != nil {
            return fmt.Errorf("failed to load config: %w", err)
        }

        // Create ETL engine
        engine, err := etl.NewEngineFromConfig(config)
        if err != nil {
            return fmt.Errorf("failed to create engine: %w", err)
        }

        // Run migration
        etlConfig := &etl.ETLConfig{
            BatchSize:       config.Options.BatchSize,
            ParallelWorkers: config.Options.ParallelWorkers,
            ErrorThreshold:  config.Options.ErrorThreshold,
            ValidateAfter:   config.Options.ValidateAfterLoad,
            DryRun:          dryRun,
        }

        if err := engine.Run(ctx, etlConfig); err != nil {
            return fmt.Errorf("migration failed: %w", err)
        }

        fmt.Println("Migration completed successfully!")
        return nil
    },
}

var validateCmd = &cobra.Command{
    Use:   "validate",
    Short: "Validate migration results",
    RunE: func(cmd *cobra.Command, args []string) error {
        configFile, _ := cmd.Flags().GetString("config")

        config, err := migration.LoadConfig(configFile)
        if err != nil {
            return fmt.Errorf("failed to load config: %w", err)
        }

        validator := etl.NewValidator()

        // Connect to databases
        // ...

        // Generate validation report
        report, err := validator.GenerateReport(context.Background(), nil, nil, config.Mappings)
        if err != nil {
            return fmt.Errorf("validation failed: %w", err)
        }

        // Print report
        printValidationReport(report)

        if !report.Summary.AllPassed {
            os.Exit(1)
        }

        return nil
    },
}

var backupCmd = &cobra.Command{
    Use:   "backup",
    Short: "Create backup before migration",
    RunE: func(cmd *cobra.Command, args []string) error {
        companyID, _ := cmd.Flags().GetString("company-id")
        description, _ := cmd.Flags().GetString("description")

        // Create backup
        // ...

        return nil
    },
}

var rollbackCmd = &cobra.Command{
    Use:   "rollback [backup-id]",
    Short: "Rollback to a previous backup",
    Args:  cobra.ExactArgs(1),
    RunE: func(cmd *cobra.Command, args []string) error {
        backupID := args[0]

        // Perform rollback
        // ...

        fmt.Printf("Rollback to %s completed\n", backupID)
        return nil
    },
}

func init() {
    // Global flags
    rootCmd.PersistentFlags().StringP("config", "c", "migration.yaml", "Config file path")

    // Run command flags
    runCmd.Flags().Bool("dry-run", false, "Run without making changes")
    runCmd.Flags().StringSlice("tables", nil, "Specific tables to migrate")

    // Backup command flags
    backupCmd.Flags().String("company-id", "", "Company ID to backup")
    backupCmd.Flags().String("description", "", "Backup description")

    rootCmd.AddCommand(runCmd)
    rootCmd.AddCommand(validateCmd)
    rootCmd.AddCommand(backupCmd)
    rootCmd.AddCommand(rollbackCmd)
}

func main() {
    if err := rootCmd.Execute(); err != nil {
        fmt.Println(err)
        os.Exit(1)
    }
}

func printValidationReport(report *etl.ValidationReport) {
    fmt.Println("\n=== Validation Report ===")
    fmt.Printf("Total Tables: %d\n", report.Summary.TotalTables)
    fmt.Printf("Passed: %d\n", report.Summary.PassedTables)
    fmt.Printf("Failed: %d\n", report.Summary.FailedTables)

    for _, tr := range report.TableReports {
        status := "PASS"
        if tr.Status != "passed" {
            status = "FAIL"
        }
        fmt.Printf("\n[%s] %s\n", status, tr.TableName)
        fmt.Printf("  Row Count: %d -> %d (%v)\n",
            tr.RowCount.SourceCount, tr.RowCount.TargetCount, tr.RowCount.Match)
    }
}
```

---

## 9. 실행 체크리스트

### 9.1 마이그레이션 전 체크리스트

```markdown
## 마이그레이션 전 체크리스트

### 1. 준비 단계

#### 소스 시스템 확인
- [ ] 소스 DB 접근 권한 확보
- [ ] 테이블/컬럼 구조 문서화
- [ ] 데이터 볼륨 확인 (레코드 수, 용량)
- [ ] 데이터 품질 이슈 파악

#### 매핑 정의
- [ ] 계정과목 매핑 완료
- [ ] 거래처 매핑 완료
- [ ] 품목 매핑 완료
- [ ] 전표 유형 매핑 완료
- [ ] 기타 코드 매핑 완료

#### 환경 준비
- [ ] 테스트 환경 구축
- [ ] 네트워크 연결 확인
- [ ] 스토리지 용량 확인
- [ ] 백업 스토리지 준비

### 2. 테스트 단계

#### 테스트 마이그레이션
- [ ] 샘플 데이터 마이그레이션
- [ ] 전체 데이터 테스트 마이그레이션
- [ ] 변환 로직 검증
- [ ] 성능 측정

#### 검증
- [ ] 건수 비교 통과
- [ ] 합계 검증 통과
- [ ] 참조 무결성 확인
- [ ] 비즈니스 규칙 검증

### 3. 최종 확인

#### 운영 준비
- [ ] 마이그레이션 일정 확정
- [ ] 다운타임 공지
- [ ] 비상 연락망 확보
- [ ] 롤백 계획 수립
- [ ] 검증 담당자 배정
```

### 9.2 마이그레이션 실행 체크리스트

```markdown
## 마이그레이션 실행 체크리스트

### D-1 (전일)
- [ ] 최종 테스트 마이그레이션 성공
- [ ] 모든 이해관계자에게 일정 공지
- [ ] 시스템 상태 정상 확인

### D-Day 실행
- [ ] 소스 시스템 읽기 전용 설정
- [ ] 백업 생성 및 확인
- [ ] 마이그레이션 스크립트 실행
- [ ] 진행 상황 모니터링
- [ ] 오류 발생시 즉시 대응

### 실행 후
- [ ] 건수 검증 완료
- [ ] 합계 검증 완료
- [ ] 샘플 데이터 육안 검증
- [ ] 주요 기능 테스트
- [ ] 사용자 확인 획득

### 완료 처리
- [ ] 마이그레이션 완료 보고
- [ ] 백업 파일 안전 보관
- [ ] 문서화 완료
- [ ] 후속 모니터링 계획
```

---

## 10. 문제 해결

### 10.1 일반적인 문제 및 해결책

| 문제 | 원인 | 해결책 |
|------|------|--------|
| 인코딩 오류 | 소스 시스템 문자셋 불일치 | 명시적 인코딩 변환 적용 |
| 날짜 형식 오류 | 날짜 포맷 불일치 | 다중 포맷 파서 적용 |
| 중복 키 오류 | 소스 데이터 중복 | 중복 제거 또는 병합 규칙 정의 |
| FK 위반 | 참조 데이터 누락 | 마스터 먼저 마이그레이션 |
| 성능 저하 | 대량 데이터 | 배치 크기 조정, 인덱스 비활성화 |

### 10.2 디버깅 쿼리

```sql
-- 마이그레이션 후 데이터 검증 쿼리

-- 1. 테이블별 건수 비교
SELECT
    'accounts' as table_name,
    COUNT(*) as record_count
FROM accounts
WHERE company_id = :company_id
UNION ALL
SELECT
    'partners',
    COUNT(*)
FROM partners
WHERE company_id = :company_id
UNION ALL
SELECT
    'vouchers',
    COUNT(*)
FROM vouchers
WHERE company_id = :company_id;

-- 2. 전표 차대변 검증
SELECT
    voucher_number,
    total_debit,
    total_credit,
    total_debit - total_credit as difference
FROM vouchers
WHERE company_id = :company_id
  AND total_debit != total_credit;

-- 3. 고아 레코드 확인
SELECT vl.id, vl.voucher_id
FROM voucher_lines vl
LEFT JOIN vouchers v ON vl.voucher_id = v.id
WHERE v.id IS NULL;

-- 4. 누락된 참조 확인
SELECT
    vl.id,
    vl.account_code,
    'account not found' as issue
FROM voucher_lines vl
WHERE vl.account_id IS NULL
  AND vl.account_code IS NOT NULL;
```

---

## 변경 이력

| 버전 | 날짜 | 작성자 | 변경 내용 |
|------|------|--------|-----------|
| 1.0 | 2025-01-xx | K-ERP Team | 최초 작성 |
