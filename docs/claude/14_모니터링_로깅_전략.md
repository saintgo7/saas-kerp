# K-ERP v0.2 - 모니터링 로깅 전략

**문서 버전**: 0.2.0
**작성일**: 2026-01-16
**상태**: 검토 대기

---

## 목차

1. [모니터링 아키텍처](#1-모니터링-아키텍처)
2. [메트릭 수집](#2-메트릭-수집)
3. [로깅 전략](#3-로깅-전략)
4. [분산 추적](#4-분산-추적)
5. [알림 설정](#5-알림-설정)

---

## 1. 모니터링 아키텍처

### 1.1 전체 아키텍처

```
┌─────────────────────────────────────────────────────────────────────────────┐
│                       Observability Architecture                             │
├─────────────────────────────────────────────────────────────────────────────┤
│                                                                             │
│  ┌─────────────────────────────────────────────────────────────────────┐   │
│  │                        Applications                                  │   │
│  │  ┌──────────────┬──────────────┬──────────────┬──────────────┐     │   │
│  │  │  Go API      │  Go Worker   │  Python      │  Python      │     │   │
│  │  │  Server      │              │  Scraper     │  Insurance   │     │   │
│  │  └──────┬───────┴──────┬───────┴──────┬───────┴──────┬───────┘     │   │
│  │         │              │              │              │              │   │
│  │         ▼              ▼              ▼              ▼              │   │
│  │  ┌──────────────────────────────────────────────────────────┐     │   │
│  │  │                 OpenTelemetry Collector                   │     │   │
│  │  └──────────────────────────────────────────────────────────┘     │   │
│  └─────────────────────────────────────────────────────────────────────┘   │
│                    │              │              │                          │
│          ┌────────┴───┐    ┌────┴────┐   ┌────┴─────┐                     │
│          ▼            ▼    ▼         ▼   ▼          ▼                     │
│  ┌──────────────┐ ┌──────────────┐ ┌──────────────┐                       │
│  │  Prometheus  │ │    Loki      │ │   Jaeger     │                       │
│  │  (Metrics)   │ │   (Logs)     │ │  (Traces)    │                       │
│  └──────┬───────┘ └──────┬───────┘ └──────┬───────┘                       │
│         │                │                │                                │
│         └────────────────┼────────────────┘                                │
│                          ▼                                                  │
│                  ┌──────────────┐                                          │
│                  │   Grafana    │                                          │
│                  │ (Dashboard)  │                                          │
│                  └──────────────┘                                          │
│                          │                                                  │
│                          ▼                                                  │
│                  ┌──────────────┐                                          │
│                  │ AlertManager │ ───▶ Slack / Email / PagerDuty          │
│                  └──────────────┘                                          │
│                                                                             │
└─────────────────────────────────────────────────────────────────────────────┘
```

### 1.2 기술 스택

| 구성요소 | 기술 | 용도 |
|----------|------|------|
| 메트릭 | Prometheus | 시계열 메트릭 저장 |
| 로그 | Loki | 로그 집계 및 검색 |
| 추적 | Jaeger | 분산 추적 |
| 대시보드 | Grafana | 시각화 |
| 알림 | AlertManager | 알림 관리 |
| 수집 | OpenTelemetry | 통합 수집 |

---

## 2. 메트릭 수집

### 2.1 Go 메트릭 설정

```go
// pkg/metrics/metrics.go
package metrics

import (
    "github.com/prometheus/client_golang/prometheus"
    "github.com/prometheus/client_golang/prometheus/promauto"
)

var (
    // HTTP 요청 메트릭
    HTTPRequestsTotal = promauto.NewCounterVec(
        prometheus.CounterOpts{
            Name: "http_requests_total",
            Help: "Total number of HTTP requests",
        },
        []string{"method", "path", "status"},
    )

    HTTPRequestDuration = promauto.NewHistogramVec(
        prometheus.HistogramOpts{
            Name:    "http_request_duration_seconds",
            Help:    "HTTP request duration in seconds",
            Buckets: []float64{.005, .01, .025, .05, .1, .25, .5, 1, 2.5, 5, 10},
        },
        []string{"method", "path"},
    )

    // 비즈니스 메트릭
    InvoicesProcessed = promauto.NewCounterVec(
        prometheus.CounterOpts{
            Name: "invoices_processed_total",
            Help: "Total number of invoices processed",
        },
        []string{"type", "provider", "status"},
    )

    InsuranceReportsSubmitted = promauto.NewCounterVec(
        prometheus.CounterOpts{
            Name: "insurance_reports_submitted_total",
            Help: "Total number of insurance reports submitted",
        },
        []string{"agency", "report_type", "status"},
    )

    // gRPC 메트릭
    GRPCRequestsTotal = promauto.NewCounterVec(
        prometheus.CounterOpts{
            Name: "grpc_requests_total",
            Help: "Total number of gRPC requests",
        },
        []string{"service", "method", "status"},
    )

    GRPCRequestDuration = promauto.NewHistogramVec(
        prometheus.HistogramOpts{
            Name:    "grpc_request_duration_seconds",
            Help:    "gRPC request duration in seconds",
            Buckets: []float64{.01, .05, .1, .25, .5, 1, 2.5, 5, 10, 30},
        },
        []string{"service", "method"},
    )

    // 데이터베이스 메트릭
    DBQueryDuration = promauto.NewHistogramVec(
        prometheus.HistogramOpts{
            Name:    "db_query_duration_seconds",
            Help:    "Database query duration in seconds",
            Buckets: []float64{.001, .005, .01, .025, .05, .1, .25, .5, 1},
        },
        []string{"query_type"},
    )

    DBConnectionsActive = promauto.NewGauge(prometheus.GaugeOpts{
        Name: "db_connections_active",
        Help: "Number of active database connections",
    })
)
```

### 2.2 HTTP 미들웨어

```go
// internal/middleware/metrics.go
package middleware

import (
    "strconv"
    "time"

    "github.com/gin-gonic/gin"
    "github.com/kerp/pkg/metrics"
)

func MetricsMiddleware() gin.HandlerFunc {
    return func(c *gin.Context) {
        start := time.Now()
        path := c.FullPath()
        if path == "" {
            path = "unknown"
        }

        c.Next()

        duration := time.Since(start).Seconds()
        status := strconv.Itoa(c.Writer.Status())

        metrics.HTTPRequestsTotal.WithLabelValues(
            c.Request.Method,
            path,
            status,
        ).Inc()

        metrics.HTTPRequestDuration.WithLabelValues(
            c.Request.Method,
            path,
        ).Observe(duration)
    }
}
```

### 2.3 Python 메트릭 설정

```python
# python-services/shared/metrics/prometheus.py
from prometheus_client import Counter, Histogram, Gauge, start_http_server
import time

# gRPC 메트릭
grpc_requests_total = Counter(
    'grpc_requests_total',
    'Total gRPC requests',
    ['service', 'method', 'status']
)

grpc_request_duration = Histogram(
    'grpc_request_duration_seconds',
    'gRPC request duration',
    ['service', 'method'],
    buckets=[.01, .05, .1, .25, .5, 1, 2.5, 5, 10, 30, 60, 120]
)

# 스크래핑 메트릭
scraping_duration = Histogram(
    'scraping_duration_seconds',
    'Web scraping duration',
    ['target'],
    buckets=[1, 5, 10, 30, 60, 120, 300]
)

scraping_errors = Counter(
    'scraping_errors_total',
    'Scraping errors',
    ['target', 'error_type']
)

# EDI 메트릭
edi_messages_sent = Counter(
    'edi_messages_sent_total',
    'EDI messages sent',
    ['agency', 'message_type', 'status']
)

# gRPC 인터셉터
class MetricsInterceptor(grpc.ServerInterceptor):
    def intercept_service(self, continuation, handler_call_details):
        start_time = time.time()
        method = handler_call_details.method.split('/')[-1]
        service = handler_call_details.method.split('/')[-2]

        try:
            response = continuation(handler_call_details)
            grpc_requests_total.labels(
                service=service,
                method=method,
                status='OK'
            ).inc()
            return response
        except Exception as e:
            grpc_requests_total.labels(
                service=service,
                method=method,
                status='ERROR'
            ).inc()
            raise
        finally:
            duration = time.time() - start_time
            grpc_request_duration.labels(
                service=service,
                method=method
            ).observe(duration)
```

### 2.4 Prometheus 설정

```yaml
# deployments/prometheus/prometheus.yml
global:
  scrape_interval: 15s
  evaluation_interval: 15s

alerting:
  alertmanagers:
    - static_configs:
        - targets:
          - alertmanager:9093

rule_files:
  - /etc/prometheus/rules/*.yml

scrape_configs:
  # Go API Server
  - job_name: 'api-server'
    kubernetes_sd_configs:
      - role: pod
    relabel_configs:
      - source_labels: [__meta_kubernetes_pod_label_app]
        regex: api-server
        action: keep
      - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]
        regex: 'true'
        action: keep

  # Go Worker
  - job_name: 'worker'
    kubernetes_sd_configs:
      - role: pod
    relabel_configs:
      - source_labels: [__meta_kubernetes_pod_label_app]
        regex: worker
        action: keep

  # Python Services
  - job_name: 'python-services'
    kubernetes_sd_configs:
      - role: pod
    relabel_configs:
      - source_labels: [__meta_kubernetes_pod_label_app]
        regex: (tax-scraper|insurance-edi)
        action: keep

  # PostgreSQL
  - job_name: 'postgresql'
    static_configs:
      - targets: ['postgres-exporter:9187']

  # Redis
  - job_name: 'redis'
    static_configs:
      - targets: ['redis-exporter:9121']

  # NATS
  - job_name: 'nats'
    static_configs:
      - targets: ['nats:8222']
```

---

## 3. 로깅 전략

### 3.1 Go 로깅 설정

```go
// pkg/logger/logger.go
package logger

import (
    "os"
    "time"

    "github.com/rs/zerolog"
    "github.com/rs/zerolog/log"
)

func Init(env string) {
    zerolog.TimeFieldFormat = time.RFC3339Nano

    if env == "development" {
        log.Logger = log.Output(zerolog.ConsoleWriter{Out: os.Stdout})
    } else {
        log.Logger = zerolog.New(os.Stdout).With().
            Timestamp().
            Str("service", "api-server").
            Logger()
    }

    zerolog.SetGlobalLevel(zerolog.InfoLevel)
    if env == "development" {
        zerolog.SetGlobalLevel(zerolog.DebugLevel)
    }
}

// 구조화된 로깅 예시
func LogRequest(requestID, method, path string, status int, duration time.Duration) {
    log.Info().
        Str("request_id", requestID).
        Str("method", method).
        Str("path", path).
        Int("status", status).
        Dur("duration", duration).
        Msg("HTTP request completed")
}

func LogBusinessEvent(companyID, eventType string, data map[string]interface{}) {
    log.Info().
        Str("company_id", companyID).
        Str("event_type", eventType).
        Fields(data).
        Msg("Business event")
}

func LogError(err error, context map[string]interface{}) {
    log.Error().
        Err(err).
        Fields(context).
        Msg("Error occurred")
}
```

### 3.2 로깅 미들웨어

```go
// internal/middleware/logging.go
package middleware

import (
    "time"

    "github.com/gin-gonic/gin"
    "github.com/google/uuid"
    "github.com/rs/zerolog/log"
)

func LoggingMiddleware() gin.HandlerFunc {
    return func(c *gin.Context) {
        requestID := c.GetHeader("X-Request-ID")
        if requestID == "" {
            requestID = uuid.New().String()
        }
        c.Set("request_id", requestID)
        c.Header("X-Request-ID", requestID)

        start := time.Now()

        c.Next()

        duration := time.Since(start)

        log.Info().
            Str("request_id", requestID).
            Str("method", c.Request.Method).
            Str("path", c.Request.URL.Path).
            Str("query", c.Request.URL.RawQuery).
            Int("status", c.Writer.Status()).
            Dur("duration", duration).
            Str("client_ip", c.ClientIP()).
            Str("user_agent", c.Request.UserAgent()).
            Msg("HTTP request")
    }
}
```

### 3.3 Python 로깅 설정

```python
# python-services/shared/logging/config.py
import structlog
import logging
import sys

def configure_logging(service_name: str, env: str = "production"):
    """Configure structured logging for Python services."""

    processors = [
        structlog.contextvars.merge_contextvars,
        structlog.processors.add_log_level,
        structlog.processors.TimeStamper(fmt="iso"),
        structlog.stdlib.add_logger_name,
    ]

    if env == "development":
        processors.append(structlog.dev.ConsoleRenderer(colors=True))
    else:
        processors.append(structlog.processors.JSONRenderer())

    structlog.configure(
        processors=processors,
        wrapper_class=structlog.stdlib.BoundLogger,
        context_class=dict,
        logger_factory=structlog.PrintLoggerFactory(),
        cache_logger_on_first_use=True,
    )

    # Standard library logging
    logging.basicConfig(
        format="%(message)s",
        stream=sys.stdout,
        level=logging.DEBUG if env == "development" else logging.INFO,
    )

    return structlog.get_logger(service=service_name)

# Usage
logger = configure_logging("tax-scraper")

logger.info("scraping_started", target="hometax", date_range="2026-01-01~2026-01-31")
logger.error("scraping_failed", target="hometax", error="Connection timeout")
```

### 3.4 Loki 설정

```yaml
# deployments/loki/loki-config.yaml
auth_enabled: false

server:
  http_listen_port: 3100
  grpc_listen_port: 9096

common:
  path_prefix: /loki
  storage:
    filesystem:
      chunks_directory: /loki/chunks
      rules_directory: /loki/rules
  replication_factor: 1
  ring:
    instance_addr: 127.0.0.1
    kvstore:
      store: inmemory

schema_config:
  configs:
    - from: 2020-10-24
      store: boltdb-shipper
      object_store: filesystem
      schema: v11
      index:
        prefix: index_
        period: 24h

ruler:
  alertmanager_url: http://alertmanager:9093

limits_config:
  enforce_metric_name: false
  reject_old_samples: true
  reject_old_samples_max_age: 168h
  ingestion_rate_mb: 16
  ingestion_burst_size_mb: 32
```

### 3.5 Promtail 설정

```yaml
# deployments/loki/promtail-config.yaml
server:
  http_listen_port: 9080
  grpc_listen_port: 0

positions:
  filename: /tmp/positions.yaml

clients:
  - url: http://loki:3100/loki/api/v1/push

scrape_configs:
  - job_name: kubernetes-pods
    kubernetes_sd_configs:
      - role: pod
    relabel_configs:
      - source_labels: [__meta_kubernetes_pod_label_app]
        target_label: app
      - source_labels: [__meta_kubernetes_namespace]
        target_label: namespace
      - source_labels: [__meta_kubernetes_pod_name]
        target_label: pod
    pipeline_stages:
      - json:
          expressions:
            level: level
            message: msg
            timestamp: time
            request_id: request_id
      - labels:
          level:
          request_id:
```

---

## 4. 분산 추적

### 4.1 OpenTelemetry 설정 (Go)

```go
// pkg/tracing/tracer.go
package tracing

import (
    "context"

    "go.opentelemetry.io/otel"
    "go.opentelemetry.io/otel/exporters/otlp/otlptrace/otlptracegrpc"
    "go.opentelemetry.io/otel/propagation"
    "go.opentelemetry.io/otel/sdk/resource"
    sdktrace "go.opentelemetry.io/otel/sdk/trace"
    semconv "go.opentelemetry.io/otel/semconv/v1.21.0"
)

func InitTracer(ctx context.Context, serviceName, collectorURL string) (*sdktrace.TracerProvider, error) {
    exporter, err := otlptracegrpc.New(ctx,
        otlptracegrpc.WithEndpoint(collectorURL),
        otlptracegrpc.WithInsecure(),
    )
    if err != nil {
        return nil, err
    }

    res, err := resource.New(ctx,
        resource.WithAttributes(
            semconv.ServiceName(serviceName),
            semconv.ServiceVersion("0.2.0"),
        ),
    )
    if err != nil {
        return nil, err
    }

    tp := sdktrace.NewTracerProvider(
        sdktrace.WithBatcher(exporter),
        sdktrace.WithResource(res),
        sdktrace.WithSampler(sdktrace.AlwaysSample()),
    )

    otel.SetTracerProvider(tp)
    otel.SetTextMapPropagator(propagation.NewCompositeTextMapPropagator(
        propagation.TraceContext{},
        propagation.Baggage{},
    ))

    return tp, nil
}
```

### 4.2 HTTP 추적 미들웨어

```go
// internal/middleware/tracing.go
package middleware

import (
    "github.com/gin-gonic/gin"
    "go.opentelemetry.io/otel"
    "go.opentelemetry.io/otel/attribute"
    "go.opentelemetry.io/otel/trace"
)

func TracingMiddleware() gin.HandlerFunc {
    tracer := otel.Tracer("api-server")

    return func(c *gin.Context) {
        ctx, span := tracer.Start(c.Request.Context(), c.FullPath(),
            trace.WithAttributes(
                attribute.String("http.method", c.Request.Method),
                attribute.String("http.url", c.Request.URL.String()),
            ),
        )
        defer span.End()

        c.Request = c.Request.WithContext(ctx)
        c.Next()

        span.SetAttributes(
            attribute.Int("http.status_code", c.Writer.Status()),
        )
    }
}
```

### 4.3 gRPC 추적 (Python)

```python
# python-services/shared/tracing/opentelemetry.py
from opentelemetry import trace
from opentelemetry.exporter.otlp.proto.grpc.trace_exporter import OTLPSpanExporter
from opentelemetry.sdk.resources import Resource
from opentelemetry.sdk.trace import TracerProvider
from opentelemetry.sdk.trace.export import BatchSpanProcessor
from opentelemetry.instrumentation.grpc import GrpcInstrumentorServer

def init_tracer(service_name: str, collector_url: str):
    """Initialize OpenTelemetry tracer."""
    resource = Resource.create({"service.name": service_name})

    provider = TracerProvider(resource=resource)
    exporter = OTLPSpanExporter(endpoint=collector_url, insecure=True)
    processor = BatchSpanProcessor(exporter)
    provider.add_span_processor(processor)

    trace.set_tracer_provider(provider)

    # Auto-instrument gRPC
    GrpcInstrumentorServer().instrument()

    return trace.get_tracer(service_name)

# Usage in scraper
tracer = init_tracer("tax-scraper", "otel-collector:4317")

async def scrape_invoices(request):
    with tracer.start_as_current_span("scrape_hometax") as span:
        span.set_attribute("date_range", f"{request.start_date}~{request.end_date}")

        # Scraping logic...

        span.set_attribute("invoices_found", len(invoices))
```

### 4.4 Jaeger 설정

```yaml
# deployments/jaeger/jaeger.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: jaeger
  namespace: kerp
spec:
  replicas: 1
  selector:
    matchLabels:
      app: jaeger
  template:
    metadata:
      labels:
        app: jaeger
    spec:
      containers:
      - name: jaeger
        image: jaegertracing/all-in-one:1.52
        ports:
        - containerPort: 16686  # UI
        - containerPort: 14268  # HTTP collector
        - containerPort: 14250  # gRPC collector
        env:
        - name: COLLECTOR_OTLP_ENABLED
          value: "true"
```

---

## 5. 알림 설정

### 5.1 AlertManager 설정

```yaml
# deployments/alertmanager/alertmanager.yml
global:
  resolve_timeout: 5m
  slack_api_url: 'https://hooks.slack.com/services/xxx'

route:
  group_by: ['alertname', 'severity']
  group_wait: 30s
  group_interval: 5m
  repeat_interval: 4h
  receiver: 'slack-critical'
  routes:
    - match:
        severity: critical
      receiver: 'slack-critical'
      continue: true
    - match:
        severity: warning
      receiver: 'slack-warning'

receivers:
  - name: 'slack-critical'
    slack_configs:
      - channel: '#kerp-alerts-critical'
        send_resolved: true
        title: '{{ .Status | toUpper }} - {{ .CommonLabels.alertname }}'
        text: |
          *Alert:* {{ .CommonLabels.alertname }}
          *Severity:* {{ .CommonLabels.severity }}
          *Description:* {{ .CommonAnnotations.description }}
          *Details:*
          {{ range .Alerts }}
            - *{{ .Labels.instance }}*: {{ .Annotations.summary }}
          {{ end }}

  - name: 'slack-warning'
    slack_configs:
      - channel: '#kerp-alerts'
        send_resolved: true
```

### 5.2 알림 규칙

```yaml
# deployments/prometheus/rules/alerts.yml
groups:
  - name: kerp-alerts
    rules:
      # API 서버 다운
      - alert: APIServerDown
        expr: up{job="api-server"} == 0
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: "API Server is down"
          description: "API Server {{ $labels.instance }} has been down for more than 1 minute."

      # 높은 에러율
      - alert: HighErrorRate
        expr: |
          sum(rate(http_requests_total{status=~"5.."}[5m])) /
          sum(rate(http_requests_total[5m])) > 0.05
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "High error rate detected"
          description: "Error rate is {{ $value | humanizePercentage }} over the last 5 minutes."

      # 느린 응답 시간
      - alert: SlowResponseTime
        expr: |
          histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket[5m])) by (le)) > 0.5
        for: 10m
        labels:
          severity: warning
        annotations:
          summary: "Slow response time"
          description: "95th percentile response time is {{ $value }}s."

      # Python 서비스 다운
      - alert: PythonServiceDown
        expr: up{job="python-services"} == 0
        for: 2m
        labels:
          severity: critical
        annotations:
          summary: "Python service is down"
          description: "{{ $labels.app }} has been down for more than 2 minutes."

      # 세금계산서 발행 실패
      - alert: InvoiceIssuanceFailure
        expr: |
          sum(rate(invoices_processed_total{status="failed"}[10m])) /
          sum(rate(invoices_processed_total[10m])) > 0.1
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "High invoice issuance failure rate"
          description: "Invoice failure rate is {{ $value | humanizePercentage }}."

      # 4대보험 신고 실패
      - alert: InsuranceReportFailure
        expr: |
          sum(rate(insurance_reports_submitted_total{status="failed"}[1h])) > 0
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "Insurance report submission failed"
          description: "Insurance report submission to {{ $labels.agency }} failed."

      # 데이터베이스 연결 부족
      - alert: DatabaseConnectionsLow
        expr: db_connections_active / db_connections_max > 0.8
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "Database connections running low"
          description: "Database connection pool is {{ $value | humanizePercentage }} utilized."
```

### 5.3 Grafana 대시보드

```json
{
  "dashboard": {
    "title": "K-ERP Overview",
    "panels": [
      {
        "title": "Request Rate",
        "type": "graph",
        "targets": [
          {
            "expr": "sum(rate(http_requests_total[5m])) by (status)",
            "legendFormat": "{{status}}"
          }
        ]
      },
      {
        "title": "Response Time (p95)",
        "type": "graph",
        "targets": [
          {
            "expr": "histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket[5m])) by (le, path))",
            "legendFormat": "{{path}}"
          }
        ]
      },
      {
        "title": "Invoice Processing",
        "type": "stat",
        "targets": [
          {
            "expr": "sum(rate(invoices_processed_total{status=\"success\"}[1h])) * 3600",
            "legendFormat": "Processed/hour"
          }
        ]
      },
      {
        "title": "Python Services Health",
        "type": "stat",
        "targets": [
          {
            "expr": "up{job=\"python-services\"}",
            "legendFormat": "{{app}}"
          }
        ]
      }
    ]
  }
}
```

---

**다음 문서**: [15_SaaS_비즈니스_모델.md](./15_SaaS_비즈니스_모델.md)
