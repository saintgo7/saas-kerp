# 14. ëª¨ë‹ˆí„°ë§ ë° ë¡œê¹… ì „ëµ

## ê°œìš”

K-ERP ì‹œìŠ¤í…œì˜ ê´€ì¸¡ì„±(Observability) êµ¬í˜„ì„ ìœ„í•œ ëª¨ë‹ˆí„°ë§, ë¡œê¹…, íŠ¸ë ˆì´ì‹± ì „ëµ.
Prometheus + Grafana + Loki ìŠ¤íƒ ê¸°ë°˜.

### ê´€ì¸¡ì„± 3ìš”ì†Œ (Observability Pillars)

| ìš”ì†Œ | ë„êµ¬ | ìš©ë„ |
|------|------|------|
| Metrics | Prometheus + Grafana | ì‹œìŠ¤í…œ ìƒíƒœ, ì„±ëŠ¥ ì§€í‘œ |
| Logs | Loki + Promtail | ì´ë²¤íŠ¸ ë¡œê·¸, ë””ë²„ê¹… |
| Traces | Jaeger / Tempo | ë¶„ì‚° ì¶”ì , ìš”ì²­ íë¦„ |

---

## 1. êµ¬ì¡°í™”ëœ ë¡œê¹…

### 1.1 ë¡œê±° ì„¤ì •

```go
// internal/infrastructure/logger/logger.go
package logger

import (
    "context"
    "os"
    "time"

    "go.uber.org/zap"
    "go.uber.org/zap/zapcore"
)

var globalLogger *zap.Logger

type Config struct {
    Level      string `env:"LOG_LEVEL" envDefault:"info"`
    Format     string `env:"LOG_FORMAT" envDefault:"json"`
    Output     string `env:"LOG_OUTPUT" envDefault:"stdout"`
    AppName    string `env:"APP_NAME" envDefault:"kerp-api"`
    AppVersion string `env:"APP_VERSION"`
}

// Init ë¡œê±° ì´ˆê¸°í™”
func Init(cfg Config) error {
    level, err := zapcore.ParseLevel(cfg.Level)
    if err != nil {
        level = zapcore.InfoLevel
    }

    encoderConfig := zapcore.EncoderConfig{
        TimeKey:        "timestamp",
        LevelKey:       "level",
        NameKey:        "logger",
        CallerKey:      "caller",
        FunctionKey:    zapcore.OmitKey,
        MessageKey:     "message",
        StacktraceKey:  "stacktrace",
        LineEnding:     zapcore.DefaultLineEnding,
        EncodeLevel:    zapcore.LowercaseLevelEncoder,
        EncodeTime:     zapcore.ISO8601TimeEncoder,
        EncodeDuration: zapcore.MillisDurationEncoder,
        EncodeCaller:   zapcore.ShortCallerEncoder,
    }

    var encoder zapcore.Encoder
    if cfg.Format == "json" {
        encoder = zapcore.NewJSONEncoder(encoderConfig)
    } else {
        encoder = zapcore.NewConsoleEncoder(encoderConfig)
    }

    var output zapcore.WriteSyncer
    if cfg.Output == "stdout" {
        output = zapcore.AddSync(os.Stdout)
    } else {
        file, err := os.OpenFile(cfg.Output, os.O_APPEND|os.O_CREATE|os.O_WRONLY, 0644)
        if err != nil {
            return err
        }
        output = zapcore.AddSync(file)
    }

    core := zapcore.NewCore(encoder, output, level)

    globalLogger = zap.New(core,
        zap.AddCaller(),
        zap.AddStacktrace(zapcore.ErrorLevel),
        zap.Fields(
            zap.String("app", cfg.AppName),
            zap.String("version", cfg.AppVersion),
        ),
    )

    return nil
}

// Logger ì „ì—­ ë¡œê±° ë°˜í™˜
func Logger() *zap.Logger {
    if globalLogger == nil {
        globalLogger, _ = zap.NewProduction()
    }
    return globalLogger
}

// Sync ë¡œê±° í”ŒëŸ¬ì‹œ
func Sync() {
    if globalLogger != nil {
        _ = globalLogger.Sync()
    }
}
```

### 1.2 ì»¨í…ìŠ¤íŠ¸ ê¸°ë°˜ ë¡œê¹…

```go
// internal/infrastructure/logger/context.go
package logger

import (
    "context"

    "github.com/google/uuid"
    "go.uber.org/zap"
)

type contextKey string

const (
    loggerKey    contextKey = "logger"
    requestIDKey contextKey = "request_id"
    userIDKey    contextKey = "user_id"
    companyIDKey contextKey = "company_id"
)

// WithRequestID ìš”ì²­ IDë¥¼ ì»¨í…ìŠ¤íŠ¸ì— ì¶”ê°€
func WithRequestID(ctx context.Context, requestID string) context.Context {
    return context.WithValue(ctx, requestIDKey, requestID)
}

// WithUserID ì‚¬ìš©ì IDë¥¼ ì»¨í…ìŠ¤íŠ¸ì— ì¶”ê°€
func WithUserID(ctx context.Context, userID uuid.UUID) context.Context {
    return context.WithValue(ctx, userIDKey, userID.String())
}

// WithCompanyID íšŒì‚¬ IDë¥¼ ì»¨í…ìŠ¤íŠ¸ì— ì¶”ê°€
func WithCompanyID(ctx context.Context, companyID uuid.UUID) context.Context {
    return context.WithValue(ctx, companyIDKey, companyID.String())
}

// FromContext ì»¨í…ìŠ¤íŠ¸ì—ì„œ ë¡œê±° ì¶”ì¶œ (í•„ë“œ í¬í•¨)
func FromContext(ctx context.Context) *zap.Logger {
    logger := Logger()

    if requestID, ok := ctx.Value(requestIDKey).(string); ok {
        logger = logger.With(zap.String("request_id", requestID))
    }

    if userID, ok := ctx.Value(userIDKey).(string); ok {
        logger = logger.With(zap.String("user_id", userID))
    }

    if companyID, ok := ctx.Value(companyIDKey).(string); ok {
        logger = logger.With(zap.String("company_id", companyID))
    }

    return logger
}

// Info ì •ë³´ ë¡œê·¸
func Info(ctx context.Context, msg string, fields ...zap.Field) {
    FromContext(ctx).Info(msg, fields...)
}

// Warn ê²½ê³  ë¡œê·¸
func Warn(ctx context.Context, msg string, fields ...zap.Field) {
    FromContext(ctx).Warn(msg, fields...)
}

// Error ì—ëŸ¬ ë¡œê·¸
func Error(ctx context.Context, msg string, fields ...zap.Field) {
    FromContext(ctx).Error(msg, fields...)
}

// Debug ë””ë²„ê·¸ ë¡œê·¸
func Debug(ctx context.Context, msg string, fields ...zap.Field) {
    FromContext(ctx).Debug(msg, fields...)
}
```

### 1.3 ìš”ì²­ ë¡œê¹… ë¯¸ë“¤ì›¨ì–´

```go
// internal/middleware/logging.go
package middleware

import (
    "bytes"
    "io"
    "time"

    "github.com/gin-gonic/gin"
    "github.com/google/uuid"
    "go.uber.org/zap"

    "k-erp/internal/infrastructure/logger"
)

// RequestLogging ìš”ì²­ ë¡œê¹… ë¯¸ë“¤ì›¨ì–´
func RequestLogging() gin.HandlerFunc {
    return func(c *gin.Context) {
        // ìš”ì²­ ID ìƒì„±
        requestID := c.GetHeader("X-Request-ID")
        if requestID == "" {
            requestID = uuid.New().String()
        }
        c.Set("request_id", requestID)
        c.Header("X-Request-ID", requestID)

        // ì»¨í…ìŠ¤íŠ¸ì— ìš”ì²­ ID ì¶”ê°€
        ctx := logger.WithRequestID(c.Request.Context(), requestID)
        c.Request = c.Request.WithContext(ctx)

        // ì‹œì‘ ì‹œê°„
        start := time.Now()

        // ìš”ì²­ ë³¸ë¬¸ ìº¡ì²˜ (ë””ë²„ê·¸ìš©)
        var requestBody []byte
        if c.Request.Body != nil {
            requestBody, _ = io.ReadAll(c.Request.Body)
            c.Request.Body = io.NopCloser(bytes.NewBuffer(requestBody))
        }

        // ì‘ë‹µ Writer ë˜í•‘
        blw := &bodyLogWriter{body: bytes.NewBufferString(""), ResponseWriter: c.Writer}
        c.Writer = blw

        // ë‹¤ìŒ í•¸ë“¤ëŸ¬ ì‹¤í–‰
        c.Next()

        // ì‘ë‹µ ì‹œê°„
        latency := time.Since(start)

        // ë¡œê·¸ í•„ë“œ
        fields := []zap.Field{
            zap.String("request_id", requestID),
            zap.String("method", c.Request.Method),
            zap.String("path", c.Request.URL.Path),
            zap.String("query", c.Request.URL.RawQuery),
            zap.Int("status", c.Writer.Status()),
            zap.Duration("latency", latency),
            zap.Int("response_size", blw.body.Len()),
            zap.String("client_ip", c.ClientIP()),
            zap.String("user_agent", c.Request.UserAgent()),
        }

        // ì‚¬ìš©ì ì •ë³´ ì¶”ê°€
        if userID, exists := c.Get("user_id"); exists {
            fields = append(fields, zap.String("user_id", userID.(string)))
        }
        if companyID, exists := c.Get("company_id"); exists {
            fields = append(fields, zap.String("company_id", companyID.(string)))
        }

        // ì—ëŸ¬ ë¡œê¹…
        if len(c.Errors) > 0 {
            fields = append(fields, zap.String("errors", c.Errors.String()))
        }

        // ë¡œê·¸ ë ˆë²¨ ê²°ì •
        status := c.Writer.Status()
        switch {
        case status >= 500:
            logger.Logger().Error("Request completed with error", fields...)
        case status >= 400:
            logger.Logger().Warn("Request completed with client error", fields...)
        default:
            logger.Logger().Info("Request completed", fields...)
        }
    }
}

type bodyLogWriter struct {
    gin.ResponseWriter
    body *bytes.Buffer
}

func (w bodyLogWriter) Write(b []byte) (int, error) {
    w.body.Write(b)
    return w.ResponseWriter.Write(b)
}
```

### 1.4 ë¡œê·¸ ì¶œë ¥ í˜•ì‹

```json
{
  "timestamp": "2024-01-15T09:30:00.123Z",
  "level": "info",
  "app": "kerp-api",
  "version": "1.0.0",
  "request_id": "abc123-def456",
  "user_id": "550e8400-e29b-41d4-a716-446655440000",
  "company_id": "660e8400-e29b-41d4-a716-446655440001",
  "message": "Request completed",
  "method": "POST",
  "path": "/api/v1/vouchers",
  "status": 201,
  "latency": 45,
  "client_ip": "192.168.1.100",
  "caller": "handler/voucher.go:42"
}
```

---

## 2. Prometheus ë©”íŠ¸ë¦­

### 2.1 ë©”íŠ¸ë¦­ ì •ì˜

```go
// internal/infrastructure/metrics/metrics.go
package metrics

import (
    "github.com/prometheus/client_golang/prometheus"
    "github.com/prometheus/client_golang/prometheus/promauto"
)

var (
    // HTTP ìš”ì²­ ë©”íŠ¸ë¦­
    HTTPRequestsTotal = promauto.NewCounterVec(
        prometheus.CounterOpts{
            Name: "http_requests_total",
            Help: "Total number of HTTP requests",
        },
        []string{"method", "path", "status"},
    )

    HTTPRequestDuration = promauto.NewHistogramVec(
        prometheus.HistogramOpts{
            Name:    "http_request_duration_seconds",
            Help:    "HTTP request duration in seconds",
            Buckets: []float64{.005, .01, .025, .05, .1, .25, .5, 1, 2.5, 5, 10},
        },
        []string{"method", "path"},
    )

    HTTPRequestSize = promauto.NewHistogramVec(
        prometheus.HistogramOpts{
            Name:    "http_request_size_bytes",
            Help:    "HTTP request size in bytes",
            Buckets: prometheus.ExponentialBuckets(100, 10, 8),
        },
        []string{"method", "path"},
    )

    HTTPResponseSize = promauto.NewHistogramVec(
        prometheus.HistogramOpts{
            Name:    "http_response_size_bytes",
            Help:    "HTTP response size in bytes",
            Buckets: prometheus.ExponentialBuckets(100, 10, 8),
        },
        []string{"method", "path"},
    )

    // ë¹„ì¦ˆë‹ˆìŠ¤ ë©”íŠ¸ë¦­
    VouchersCreated = promauto.NewCounterVec(
        prometheus.CounterOpts{
            Name: "vouchers_created_total",
            Help: "Total number of vouchers created",
        },
        []string{"company_id", "voucher_type"},
    )

    VouchersApproved = promauto.NewCounterVec(
        prometheus.CounterOpts{
            Name: "vouchers_approved_total",
            Help: "Total number of vouchers approved",
        },
        []string{"company_id"},
    )

    TaxInvoicesIssued = promauto.NewCounterVec(
        prometheus.CounterOpts{
            Name: "tax_invoices_issued_total",
            Help: "Total number of tax invoices issued",
        },
        []string{"company_id", "status"},
    )

    PayrollProcessed = promauto.NewCounterVec(
        prometheus.CounterOpts{
            Name: "payroll_processed_total",
            Help: "Total number of payroll periods processed",
        },
        []string{"company_id"},
    )

    // ë°ì´í„°ë² ì´ìŠ¤ ë©”íŠ¸ë¦­
    DBQueryDuration = promauto.NewHistogramVec(
        prometheus.HistogramOpts{
            Name:    "db_query_duration_seconds",
            Help:    "Database query duration in seconds",
            Buckets: []float64{.001, .005, .01, .025, .05, .1, .25, .5, 1},
        },
        []string{"operation", "table"},
    )

    DBConnectionsOpen = promauto.NewGauge(
        prometheus.GaugeOpts{
            Name: "db_connections_open",
            Help: "Number of open database connections",
        },
    )

    DBConnectionsInUse = promauto.NewGauge(
        prometheus.GaugeOpts{
            Name: "db_connections_in_use",
            Help: "Number of database connections in use",
        },
    )

    // ìºì‹œ ë©”íŠ¸ë¦­
    CacheHits = promauto.NewCounterVec(
        prometheus.CounterOpts{
            Name: "cache_hits_total",
            Help: "Total number of cache hits",
        },
        []string{"cache_type"},
    )

    CacheMisses = promauto.NewCounterVec(
        prometheus.CounterOpts{
            Name: "cache_misses_total",
            Help: "Total number of cache misses",
        },
        []string{"cache_type"},
    )

    // ì™¸ë¶€ API ë©”íŠ¸ë¦­
    ExternalAPIRequestDuration = promauto.NewHistogramVec(
        prometheus.HistogramOpts{
            Name:    "external_api_request_duration_seconds",
            Help:    "External API request duration in seconds",
            Buckets: []float64{.1, .25, .5, 1, 2.5, 5, 10},
        },
        []string{"api", "endpoint", "status"},
    )

    ExternalAPIErrors = promauto.NewCounterVec(
        prometheus.CounterOpts{
            Name: "external_api_errors_total",
            Help: "Total number of external API errors",
        },
        []string{"api", "error_type"},
    )

    // ì‘ì—… í ë©”íŠ¸ë¦­
    JobsProcessed = promauto.NewCounterVec(
        prometheus.CounterOpts{
            Name: "jobs_processed_total",
            Help: "Total number of background jobs processed",
        },
        []string{"job_type", "status"},
    )

    JobProcessingDuration = promauto.NewHistogramVec(
        prometheus.HistogramOpts{
            Name:    "job_processing_duration_seconds",
            Help:    "Job processing duration in seconds",
            Buckets: []float64{.1, .5, 1, 5, 10, 30, 60, 120},
        },
        []string{"job_type"},
    )

    JobsInQueue = promauto.NewGaugeVec(
        prometheus.GaugeOpts{
            Name: "jobs_in_queue",
            Help: "Number of jobs waiting in queue",
        },
        []string{"queue_name"},
    )
)
```

### 2.2 ë©”íŠ¸ë¦­ ë¯¸ë“¤ì›¨ì–´

```go
// internal/middleware/metrics.go
package middleware

import (
    "strconv"
    "time"

    "github.com/gin-gonic/gin"

    "k-erp/internal/infrastructure/metrics"
)

// Metrics Prometheus ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ë¯¸ë“¤ì›¨ì–´
func Metrics() gin.HandlerFunc {
    return func(c *gin.Context) {
        start := time.Now()

        // ìš”ì²­ í¬ê¸°
        requestSize := float64(c.Request.ContentLength)
        if requestSize < 0 {
            requestSize = 0
        }

        // ë‹¤ìŒ í•¸ë“¤ëŸ¬ ì‹¤í–‰
        c.Next()

        // ì‘ë‹µ ì‹œê°„
        duration := time.Since(start).Seconds()

        // ê²½ë¡œ ì •ê·œí™” (íŒŒë¼ë¯¸í„° ì œê±°)
        path := c.FullPath()
        if path == "" {
            path = "unknown"
        }

        method := c.Request.Method
        status := strconv.Itoa(c.Writer.Status())
        responseSize := float64(c.Writer.Size())

        // ë©”íŠ¸ë¦­ ê¸°ë¡
        metrics.HTTPRequestsTotal.WithLabelValues(method, path, status).Inc()
        metrics.HTTPRequestDuration.WithLabelValues(method, path).Observe(duration)
        metrics.HTTPRequestSize.WithLabelValues(method, path).Observe(requestSize)
        metrics.HTTPResponseSize.WithLabelValues(method, path).Observe(responseSize)
    }
}
```

### 2.3 GORM ë©”íŠ¸ë¦­ í”ŒëŸ¬ê·¸ì¸

```go
// internal/infrastructure/metrics/gorm_plugin.go
package metrics

import (
    "time"

    "gorm.io/gorm"
)

// GORMMetricsPlugin GORM ë©”íŠ¸ë¦­ í”ŒëŸ¬ê·¸ì¸
type GORMMetricsPlugin struct{}

func (p *GORMMetricsPlugin) Name() string {
    return "gorm:metrics"
}

func (p *GORMMetricsPlugin) Initialize(db *gorm.DB) error {
    // Query ì½œë°±
    db.Callback().Query().Before("gorm:query").Register("metrics:before_query", func(db *gorm.DB) {
        db.InstanceSet("metrics:start_time", time.Now())
    })

    db.Callback().Query().After("gorm:query").Register("metrics:after_query", func(db *gorm.DB) {
        recordQueryMetrics(db, "query")
    })

    // Create ì½œë°±
    db.Callback().Create().Before("gorm:create").Register("metrics:before_create", func(db *gorm.DB) {
        db.InstanceSet("metrics:start_time", time.Now())
    })

    db.Callback().Create().After("gorm:create").Register("metrics:after_create", func(db *gorm.DB) {
        recordQueryMetrics(db, "create")
    })

    // Update ì½œë°±
    db.Callback().Update().Before("gorm:update").Register("metrics:before_update", func(db *gorm.DB) {
        db.InstanceSet("metrics:start_time", time.Now())
    })

    db.Callback().Update().After("gorm:update").Register("metrics:after_update", func(db *gorm.DB) {
        recordQueryMetrics(db, "update")
    })

    // Delete ì½œë°±
    db.Callback().Delete().Before("gorm:delete").Register("metrics:before_delete", func(db *gorm.DB) {
        db.InstanceSet("metrics:start_time", time.Now())
    })

    db.Callback().Delete().After("gorm:delete").Register("metrics:after_delete", func(db *gorm.DB) {
        recordQueryMetrics(db, "delete")
    })

    return nil
}

func recordQueryMetrics(db *gorm.DB, operation string) {
    startTime, ok := db.InstanceGet("metrics:start_time")
    if !ok {
        return
    }

    duration := time.Since(startTime.(time.Time)).Seconds()
    table := db.Statement.Table

    DBQueryDuration.WithLabelValues(operation, table).Observe(duration)
}
```

---

## 3. Grafana ëŒ€ì‹œë³´ë“œ

### 3.1 API ì„±ëŠ¥ ëŒ€ì‹œë³´ë“œ (JSON)

```json
{
  "dashboard": {
    "title": "K-ERP API Performance",
    "panels": [
      {
        "title": "Request Rate",
        "type": "graph",
        "targets": [
          {
            "expr": "sum(rate(http_requests_total[5m])) by (path)",
            "legendFormat": "{{path}}"
          }
        ]
      },
      {
        "title": "Response Time (p95)",
        "type": "graph",
        "targets": [
          {
            "expr": "histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket[5m])) by (le, path))",
            "legendFormat": "{{path}}"
          }
        ]
      },
      {
        "title": "Error Rate",
        "type": "graph",
        "targets": [
          {
            "expr": "sum(rate(http_requests_total{status=~\"5..\"}[5m])) / sum(rate(http_requests_total[5m])) * 100",
            "legendFormat": "Error %"
          }
        ]
      },
      {
        "title": "Request by Status",
        "type": "piechart",
        "targets": [
          {
            "expr": "sum(increase(http_requests_total[1h])) by (status)",
            "legendFormat": "{{status}}"
          }
        ]
      },
      {
        "title": "Database Query Duration (p95)",
        "type": "graph",
        "targets": [
          {
            "expr": "histogram_quantile(0.95, sum(rate(db_query_duration_seconds_bucket[5m])) by (le, operation))",
            "legendFormat": "{{operation}}"
          }
        ]
      },
      {
        "title": "Cache Hit Ratio",
        "type": "gauge",
        "targets": [
          {
            "expr": "sum(rate(cache_hits_total[5m])) / (sum(rate(cache_hits_total[5m])) + sum(rate(cache_misses_total[5m]))) * 100"
          }
        ]
      }
    ]
  }
}
```

### 3.2 ë¹„ì¦ˆë‹ˆìŠ¤ ë©”íŠ¸ë¦­ ëŒ€ì‹œë³´ë“œ

```json
{
  "dashboard": {
    "title": "K-ERP Business Metrics",
    "panels": [
      {
        "title": "Vouchers Created Today",
        "type": "stat",
        "targets": [
          {
            "expr": "sum(increase(vouchers_created_total[24h]))"
          }
        ]
      },
      {
        "title": "Tax Invoices Issued Today",
        "type": "stat",
        "targets": [
          {
            "expr": "sum(increase(tax_invoices_issued_total{status=\"success\"}[24h]))"
          }
        ]
      },
      {
        "title": "Vouchers by Type",
        "type": "piechart",
        "targets": [
          {
            "expr": "sum(increase(vouchers_created_total[24h])) by (voucher_type)",
            "legendFormat": "{{voucher_type}}"
          }
        ]
      },
      {
        "title": "Popbill API Latency",
        "type": "graph",
        "targets": [
          {
            "expr": "histogram_quantile(0.95, sum(rate(external_api_request_duration_seconds_bucket{api=\"popbill\"}[5m])) by (le, endpoint))",
            "legendFormat": "{{endpoint}}"
          }
        ]
      },
      {
        "title": "External API Errors",
        "type": "graph",
        "targets": [
          {
            "expr": "sum(rate(external_api_errors_total[5m])) by (api, error_type)",
            "legendFormat": "{{api}} - {{error_type}}"
          }
        ]
      },
      {
        "title": "Background Jobs Queue",
        "type": "graph",
        "targets": [
          {
            "expr": "jobs_in_queue",
            "legendFormat": "{{queue_name}}"
          }
        ]
      }
    ]
  }
}
```

---

## 4. ì•Œë¦¼ ê·œì¹™

### 4.1 Prometheus Alert Rules

```yaml
# monitoring/prometheus/alerts/api-alerts.yml
groups:
  - name: api-alerts
    rules:
      # ë†’ì€ ì—ëŸ¬ìœ¨
      - alert: HighErrorRate
        expr: |
          sum(rate(http_requests_total{status=~"5.."}[5m])) /
          sum(rate(http_requests_total[5m])) > 0.05
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: "High error rate detected"
          description: "Error rate is {{ $value | humanizePercentage }} (threshold: 5%)"

      # ëŠë¦° ì‘ë‹µ ì‹œê°„
      - alert: SlowResponseTime
        expr: |
          histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket[5m])) by (le))
          > 1
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "Slow API response time"
          description: "95th percentile response time is {{ $value | humanizeDuration }}"

      # API ë‹¤ìš´
      - alert: APIDown
        expr: up{job="kerp-api"} == 0
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: "API server is down"
          description: "API server {{ $labels.instance }} is not responding"

      # ë†’ì€ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰
      - alert: HighMemoryUsage
        expr: |
          process_resident_memory_bytes / 1024 / 1024 > 1024
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "High memory usage"
          description: "Memory usage is {{ $value | humanize }}MB"

  - name: database-alerts
    rules:
      # ëŠë¦° ì¿¼ë¦¬
      - alert: SlowDatabaseQueries
        expr: |
          histogram_quantile(0.95, sum(rate(db_query_duration_seconds_bucket[5m])) by (le))
          > 0.5
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "Slow database queries detected"
          description: "95th percentile query time is {{ $value | humanizeDuration }}"

      # DB ì—°ê²° í’€ ê³ ê°ˆ
      - alert: DatabaseConnectionPoolExhausted
        expr: |
          db_connections_in_use / db_connections_open > 0.9
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: "Database connection pool nearly exhausted"
          description: "{{ $value | humanizePercentage }} of connections are in use"

  - name: cache-alerts
    rules:
      # ë‚®ì€ ìºì‹œ íˆíŠ¸ìœ¨
      - alert: LowCacheHitRatio
        expr: |
          sum(rate(cache_hits_total[5m])) /
          (sum(rate(cache_hits_total[5m])) + sum(rate(cache_misses_total[5m])))
          < 0.8
        for: 10m
        labels:
          severity: warning
        annotations:
          summary: "Low cache hit ratio"
          description: "Cache hit ratio is {{ $value | humanizePercentage }}"

  - name: external-api-alerts
    rules:
      # Popbill API ì—ëŸ¬
      - alert: PopbillAPIErrors
        expr: |
          sum(rate(external_api_errors_total{api="popbill"}[5m])) > 0.1
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: "Popbill API errors detected"
          description: "Popbill API error rate is {{ $value }}/s"

      # ì™¸ë¶€ API íƒ€ì„ì•„ì›ƒ
      - alert: ExternalAPITimeout
        expr: |
          histogram_quantile(0.99, sum(rate(external_api_request_duration_seconds_bucket[5m])) by (le, api))
          > 10
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "External API timeout"
          description: "{{ $labels.api }} API 99th percentile latency is {{ $value | humanizeDuration }}"

  - name: business-alerts
    rules:
      # ì „í‘œ ì²˜ë¦¬ ê¸‰ì¦
      - alert: VoucherProcessingSurge
        expr: |
          sum(rate(vouchers_created_total[5m])) >
          sum(rate(vouchers_created_total[1h] offset 1d)) * 2
        for: 10m
        labels:
          severity: info
        annotations:
          summary: "Voucher processing surge"
          description: "Voucher creation rate is 2x higher than usual"

      # ì„¸ê¸ˆê³„ì‚°ì„œ ë°œí–‰ ì‹¤íŒ¨ ê¸‰ì¦
      - alert: TaxInvoiceFailureSpike
        expr: |
          sum(rate(tax_invoices_issued_total{status="failure"}[5m])) /
          sum(rate(tax_invoices_issued_total[5m])) > 0.1
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: "Tax invoice issuance failures"
          description: "{{ $value | humanizePercentage }} of tax invoices are failing"
```

### 4.2 Alertmanager ì„¤ì •

```yaml
# monitoring/alertmanager/config.yml
global:
  resolve_timeout: 5m
  slack_api_url: '${SLACK_WEBHOOK_URL}'

route:
  group_by: ['alertname', 'severity']
  group_wait: 30s
  group_interval: 5m
  repeat_interval: 4h
  receiver: 'default'
  routes:
    - match:
        severity: critical
      receiver: 'critical'
      continue: true
    - match:
        severity: warning
      receiver: 'warning'

receivers:
  - name: 'default'
    slack_configs:
      - channel: '#kerp-alerts'
        send_resolved: true
        title: '{{ .Status | toUpper }}: {{ .CommonAnnotations.summary }}'
        text: '{{ .CommonAnnotations.description }}'

  - name: 'critical'
    slack_configs:
      - channel: '#kerp-alerts-critical'
        send_resolved: true
        title: 'ğŸš¨ CRITICAL: {{ .CommonAnnotations.summary }}'
        text: '{{ .CommonAnnotations.description }}'
    pagerduty_configs:
      - service_key: '${PAGERDUTY_SERVICE_KEY}'

  - name: 'warning'
    slack_configs:
      - channel: '#kerp-alerts'
        send_resolved: true
        title: 'âš ï¸ WARNING: {{ .CommonAnnotations.summary }}'
        text: '{{ .CommonAnnotations.description }}'

inhibit_rules:
  - source_match:
      severity: 'critical'
    target_match:
      severity: 'warning'
    equal: ['alertname']
```

---

## 5. ë¶„ì‚° ì¶”ì  (Distributed Tracing)

### 5.1 OpenTelemetry ì„¤ì •

```go
// internal/infrastructure/tracing/otel.go
package tracing

import (
    "context"
    "fmt"

    "go.opentelemetry.io/otel"
    "go.opentelemetry.io/otel/attribute"
    "go.opentelemetry.io/otel/exporters/otlp/otlptrace/otlptracegrpc"
    "go.opentelemetry.io/otel/propagation"
    "go.opentelemetry.io/otel/sdk/resource"
    sdktrace "go.opentelemetry.io/otel/sdk/trace"
    semconv "go.opentelemetry.io/otel/semconv/v1.21.0"
    "go.opentelemetry.io/otel/trace"
)

type Config struct {
    ServiceName    string `env:"OTEL_SERVICE_NAME" envDefault:"kerp-api"`
    ServiceVersion string `env:"OTEL_SERVICE_VERSION"`
    Endpoint       string `env:"OTEL_EXPORTER_ENDPOINT" envDefault:"localhost:4317"`
    Enabled        bool   `env:"OTEL_ENABLED" envDefault:"true"`
    SampleRate     float64 `env:"OTEL_SAMPLE_RATE" envDefault:"1.0"`
}

var tracer trace.Tracer

// Init OpenTelemetry ì´ˆê¸°í™”
func Init(ctx context.Context, cfg Config) (func(), error) {
    if !cfg.Enabled {
        tracer = otel.Tracer(cfg.ServiceName)
        return func() {}, nil
    }

    // OTLP Exporter
    exporter, err := otlptracegrpc.New(ctx,
        otlptracegrpc.WithEndpoint(cfg.Endpoint),
        otlptracegrpc.WithInsecure(),
    )
    if err != nil {
        return nil, fmt.Errorf("failed to create exporter: %w", err)
    }

    // Resource
    res, err := resource.Merge(
        resource.Default(),
        resource.NewWithAttributes(
            semconv.SchemaURL,
            semconv.ServiceName(cfg.ServiceName),
            semconv.ServiceVersion(cfg.ServiceVersion),
            attribute.String("environment", "production"),
        ),
    )
    if err != nil {
        return nil, fmt.Errorf("failed to create resource: %w", err)
    }

    // Sampler
    sampler := sdktrace.ParentBased(
        sdktrace.TraceIDRatioBased(cfg.SampleRate),
    )

    // TracerProvider
    tp := sdktrace.NewTracerProvider(
        sdktrace.WithBatcher(exporter),
        sdktrace.WithResource(res),
        sdktrace.WithSampler(sampler),
    )

    otel.SetTracerProvider(tp)
    otel.SetTextMapPropagator(propagation.NewCompositeTextMapPropagator(
        propagation.TraceContext{},
        propagation.Baggage{},
    ))

    tracer = tp.Tracer(cfg.ServiceName)

    cleanup := func() {
        if err := tp.Shutdown(ctx); err != nil {
            fmt.Printf("Error shutting down tracer provider: %v\n", err)
        }
    }

    return cleanup, nil
}

// Tracer ì „ì—­ Tracer ë°˜í™˜
func Tracer() trace.Tracer {
    if tracer == nil {
        tracer = otel.Tracer("kerp-api")
    }
    return tracer
}

// StartSpan ìƒˆ ìŠ¤íŒ¬ ì‹œì‘
func StartSpan(ctx context.Context, name string, opts ...trace.SpanStartOption) (context.Context, trace.Span) {
    return Tracer().Start(ctx, name, opts...)
}
```

### 5.2 íŠ¸ë ˆì´ì‹± ë¯¸ë“¤ì›¨ì–´

```go
// internal/middleware/tracing.go
package middleware

import (
    "github.com/gin-gonic/gin"
    "go.opentelemetry.io/otel"
    "go.opentelemetry.io/otel/attribute"
    "go.opentelemetry.io/otel/propagation"
    "go.opentelemetry.io/otel/trace"
)

// Tracing OpenTelemetry íŠ¸ë ˆì´ì‹± ë¯¸ë“¤ì›¨ì–´
func Tracing(serviceName string) gin.HandlerFunc {
    tracer := otel.Tracer(serviceName)
    propagator := otel.GetTextMapPropagator()

    return func(c *gin.Context) {
        // ì»¨í…ìŠ¤íŠ¸ ì¶”ì¶œ
        ctx := propagator.Extract(c.Request.Context(), propagation.HeaderCarrier(c.Request.Header))

        // ìŠ¤íŒ¬ ìƒì„±
        ctx, span := tracer.Start(ctx, c.FullPath(),
            trace.WithSpanKind(trace.SpanKindServer),
            trace.WithAttributes(
                attribute.String("http.method", c.Request.Method),
                attribute.String("http.url", c.Request.URL.String()),
                attribute.String("http.host", c.Request.Host),
                attribute.String("http.user_agent", c.Request.UserAgent()),
                attribute.String("net.peer.ip", c.ClientIP()),
            ),
        )
        defer span.End()

        // ìš”ì²­ IDë¥¼ trace IDë¡œ ì„¤ì •
        c.Set("trace_id", span.SpanContext().TraceID().String())
        c.Header("X-Trace-ID", span.SpanContext().TraceID().String())

        // ì»¨í…ìŠ¤íŠ¸ ì „íŒŒ
        c.Request = c.Request.WithContext(ctx)

        // ë‹¤ìŒ í•¸ë“¤ëŸ¬ ì‹¤í–‰
        c.Next()

        // ì‘ë‹µ ì •ë³´ ì¶”ê°€
        span.SetAttributes(
            attribute.Int("http.status_code", c.Writer.Status()),
            attribute.Int("http.response_size", c.Writer.Size()),
        )

        // ì—ëŸ¬ ê¸°ë¡
        if len(c.Errors) > 0 {
            span.RecordError(c.Errors.Last().Err)
            span.SetAttributes(attribute.String("error.message", c.Errors.String()))
        }
    }
}
```

---

## 6. ë¡œê·¸ ìˆ˜ì§‘ (Loki)

### 6.1 Promtail ì„¤ì •

```yaml
# monitoring/promtail/config.yml
server:
  http_listen_port: 9080
  grpc_listen_port: 0

positions:
  filename: /tmp/positions.yaml

clients:
  - url: http://loki:3100/loki/api/v1/push

scrape_configs:
  # Kubernetes íŒŒë“œ ë¡œê·¸
  - job_name: kubernetes-pods
    kubernetes_sd_configs:
      - role: pod
    relabel_configs:
      - source_labels: [__meta_kubernetes_pod_label_app]
        target_label: app
      - source_labels: [__meta_kubernetes_pod_name]
        target_label: pod
      - source_labels: [__meta_kubernetes_namespace]
        target_label: namespace
      - source_labels: [__meta_kubernetes_pod_container_name]
        target_label: container
    pipeline_stages:
      - json:
          expressions:
            level: level
            timestamp: timestamp
            message: message
            request_id: request_id
            user_id: user_id
            company_id: company_id
      - labels:
          level:
          request_id:
      - timestamp:
          source: timestamp
          format: RFC3339
```

### 6.2 Loki ì¿¼ë¦¬ ì˜ˆì‹œ

```logql
# ì—ëŸ¬ ë¡œê·¸ ì¡°íšŒ
{app="kerp-api"} | json | level="error"

# íŠ¹ì • ìš”ì²­ ID ì¶”ì 
{app="kerp-api"} | json | request_id="abc123-def456"

# íŠ¹ì • ì‚¬ìš©ìì˜ í™œë™
{app="kerp-api"} | json | user_id="550e8400-e29b-41d4-a716-446655440000"

# ëŠë¦° ìš”ì²­ (1ì´ˆ ì´ìƒ)
{app="kerp-api"} | json | latency > 1000

# íŠ¹ì • ê²½ë¡œì˜ ì—ëŸ¬
{app="kerp-api"} | json | path="/api/v1/vouchers" | level="error"

# ì‹œê°„ëŒ€ë³„ ì—ëŸ¬ ì¹´ìš´íŠ¸
sum(count_over_time({app="kerp-api"} | json | level="error" [5m])) by (path)
```

---

## 7. í—¬ìŠ¤ì²´í¬

### 7.1 í—¬ìŠ¤ì²´í¬ ì—”ë“œí¬ì¸íŠ¸

```go
// internal/handler/health_handler.go
package handler

import (
    "context"
    "net/http"
    "time"

    "github.com/gin-gonic/gin"
    "gorm.io/gorm"

    redisclient "k-erp/internal/infrastructure/redis"
)

type HealthHandler struct {
    db    *gorm.DB
    redis *redisclient.Client
}

func NewHealthHandler(db *gorm.DB, redis *redisclient.Client) *HealthHandler {
    return &HealthHandler{db: db, redis: redis}
}

// LivenessProbe ì‚´ì•„ìˆëŠ”ì§€ í™•ì¸
// @Summary Liveness probe
// @Tags Health
// @Success 200 {object} map[string]string
// @Router /health/live [get]
func (h *HealthHandler) LivenessProbe(c *gin.Context) {
    c.JSON(http.StatusOK, gin.H{
        "status": "ok",
        "time":   time.Now().Format(time.RFC3339),
    })
}

// ReadinessProbe ì¤€ë¹„ë˜ì—ˆëŠ”ì§€ í™•ì¸ (ì˜ì¡´ì„± ì²´í¬)
// @Summary Readiness probe
// @Tags Health
// @Success 200 {object} map[string]interface{}
// @Failure 503 {object} map[string]interface{}
// @Router /health/ready [get]
func (h *HealthHandler) ReadinessProbe(c *gin.Context) {
    ctx, cancel := context.WithTimeout(c.Request.Context(), 5*time.Second)
    defer cancel()

    checks := make(map[string]string)
    allHealthy := true

    // Database check
    sqlDB, err := h.db.DB()
    if err != nil {
        checks["database"] = "error: " + err.Error()
        allHealthy = false
    } else if err := sqlDB.PingContext(ctx); err != nil {
        checks["database"] = "error: " + err.Error()
        allHealthy = false
    } else {
        checks["database"] = "ok"
    }

    // Redis check
    if err := h.redis.Ping(ctx); err != nil {
        checks["redis"] = "error: " + err.Error()
        allHealthy = false
    } else {
        checks["redis"] = "ok"
    }

    response := gin.H{
        "status": "ok",
        "checks": checks,
        "time":   time.Now().Format(time.RFC3339),
    }

    if !allHealthy {
        response["status"] = "unhealthy"
        c.JSON(http.StatusServiceUnavailable, response)
        return
    }

    c.JSON(http.StatusOK, response)
}

// VersionInfo ë²„ì „ ì •ë³´
// @Summary Version info
// @Tags Health
// @Success 200 {object} map[string]string
// @Router /health/version [get]
func (h *HealthHandler) VersionInfo(c *gin.Context) {
    c.JSON(http.StatusOK, gin.H{
        "version":    Version,
        "commit":     Commit,
        "build_time": BuildTime,
        "go_version": GoVersion,
    })
}

// ë¹Œë“œ ì‹œ ì£¼ì…ë˜ëŠ” ë³€ìˆ˜
var (
    Version   = "dev"
    Commit    = "unknown"
    BuildTime = "unknown"
    GoVersion = "unknown"
)
```

---

## 8. ì¸í”„ë¼ êµ¬ì„±

### 8.1 Docker Compose (ëª¨ë‹ˆí„°ë§ ìŠ¤íƒ)

```yaml
# docker-compose.monitoring.yml
version: '3.8'

services:
  prometheus:
    image: prom/prometheus:v2.48.0
    volumes:
      - ./monitoring/prometheus:/etc/prometheus
      - prometheus-data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--storage.tsdb.retention.time=30d'
      - '--web.enable-lifecycle'
    ports:
      - "9090:9090"

  alertmanager:
    image: prom/alertmanager:v0.26.0
    volumes:
      - ./monitoring/alertmanager:/etc/alertmanager
    command:
      - '--config.file=/etc/alertmanager/config.yml'
    ports:
      - "9093:9093"

  grafana:
    image: grafana/grafana:10.2.2
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_ADMIN_PASSWORD}
      - GF_USERS_ALLOW_SIGN_UP=false
    volumes:
      - ./monitoring/grafana/provisioning:/etc/grafana/provisioning
      - grafana-data:/var/lib/grafana
    ports:
      - "3001:3000"
    depends_on:
      - prometheus

  loki:
    image: grafana/loki:2.9.2
    volumes:
      - ./monitoring/loki:/etc/loki
      - loki-data:/loki
    command: -config.file=/etc/loki/config.yml
    ports:
      - "3100:3100"

  promtail:
    image: grafana/promtail:2.9.2
    volumes:
      - ./monitoring/promtail:/etc/promtail
      - /var/log:/var/log:ro
    command: -config.file=/etc/promtail/config.yml
    depends_on:
      - loki

  jaeger:
    image: jaegertracing/all-in-one:1.52
    environment:
      - COLLECTOR_OTLP_ENABLED=true
    ports:
      - "16686:16686"  # UI
      - "4317:4317"    # OTLP gRPC
      - "4318:4318"    # OTLP HTTP

volumes:
  prometheus-data:
  grafana-data:
  loki-data:
```

### 8.2 Prometheus ì„¤ì •

```yaml
# monitoring/prometheus/prometheus.yml
global:
  scrape_interval: 15s
  evaluation_interval: 15s

alerting:
  alertmanagers:
    - static_configs:
        - targets:
            - alertmanager:9093

rule_files:
  - /etc/prometheus/alerts/*.yml

scrape_configs:
  - job_name: 'prometheus'
    static_configs:
      - targets: ['localhost:9090']

  - job_name: 'kerp-api'
    kubernetes_sd_configs:
      - role: pod
    relabel_configs:
      - source_labels: [__meta_kubernetes_pod_label_app]
        regex: kerp-api
        action: keep
      - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]
        regex: "true"
        action: keep
      - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_path]
        target_label: __metrics_path__
        regex: (.+)
      - source_labels: [__address__, __meta_kubernetes_pod_annotation_prometheus_io_port]
        action: replace
        regex: ([^:]+)(?::\d+)?;(\d+)
        replacement: $1:$2
        target_label: __address__

  - job_name: 'postgres'
    static_configs:
      - targets: ['postgres-exporter:9187']

  - job_name: 'redis'
    static_configs:
      - targets: ['redis-exporter:9121']
```

---

## 9. ì²´í¬ë¦¬ìŠ¤íŠ¸

### ëª¨ë‹ˆí„°ë§ êµ¬í˜„ ì²´í¬ë¦¬ìŠ¤íŠ¸

- [ ] êµ¬ì¡°í™”ëœ ë¡œê¹… (zap)
- [ ] ì»¨í…ìŠ¤íŠ¸ ê¸°ë°˜ ë¡œê¹… (request_id, user_id)
- [ ] ìš”ì²­ ë¡œê¹… ë¯¸ë“¤ì›¨ì–´
- [ ] Prometheus ë©”íŠ¸ë¦­ (HTTP, DB, Cache)
- [ ] ë¹„ì¦ˆë‹ˆìŠ¤ ë©”íŠ¸ë¦­ (ì „í‘œ, ì„¸ê¸ˆê³„ì‚°ì„œ)
- [ ] GORM ë©”íŠ¸ë¦­ í”ŒëŸ¬ê·¸ì¸
- [ ] Grafana ëŒ€ì‹œë³´ë“œ
- [ ] ì•Œë¦¼ ê·œì¹™ (Prometheus Alertmanager)
- [ ] OpenTelemetry ë¶„ì‚° ì¶”ì 
- [ ] Loki ë¡œê·¸ ìˆ˜ì§‘
- [ ] í—¬ìŠ¤ì²´í¬ ì—”ë“œí¬ì¸íŠ¸

### SLO (Service Level Objectives)

| ì§€í‘œ | ëª©í‘œ | ì¸¡ì • ë°©ë²• |
|------|------|----------|
| ê°€ìš©ì„± | 99.9% | `up` ë©”íŠ¸ë¦­ |
| ì‘ë‹µì‹œê°„ (p95) | < 200ms | `http_request_duration_seconds` |
| ì—ëŸ¬ìœ¨ | < 0.1% | `http_requests_total{status=~"5.."}` |
| ìºì‹œ íˆíŠ¸ìœ¨ | > 90% | `cache_hits_total` / total |
